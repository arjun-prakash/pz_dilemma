{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'crd_v0' from 'src.environments' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-4ed38556f3be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrd_v0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupersuit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpettingzoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'crd_v0' from 'src.environments' (unknown location)"
     ]
    }
   ],
   "source": [
    "from src.environments import crd_v0\n",
    "import supersuit as ss\n",
    "from pettingzoo.utils.conversions import to_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delimma!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3), 'player_2': Discrete(3), 'player_3': Discrete(3), 'player_4': Discrete(3), 'player_5': Discrete(3)}\n"
     ]
    }
   ],
   "source": [
    "env = crd_v0.env()\n",
    "#env = rpsls_v1.env()\n",
    "\n",
    "\n",
    "#env = ss.agent_indicator_v0(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current moves of: player_0 , WAITING with 100\n",
      "Current moves of: player_1 , WAITING with 100\n",
      "Current moves of: player_2 , WAITING with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , WAITING with 100\n",
      "Current moves of: player_2 , WAITING with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , WAITING with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 90.0\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 10.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 90.0\n",
      "Current moves of: player_3 , COOPERATE with 90.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 20.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 90.0\n",
      "Current moves of: player_3 , COOPERATE with 90.0\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 20.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 90.0\n",
      "Current moves of: player_3 , COOPERATE with 90.0\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': -0.10536051565782628, 'player_3': -0.10536051565782628, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 20.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , COOPERATE with 90.0\n",
      "Current moves of: player_1 , WAITING with 100\n",
      "Current moves of: player_2 , WAITING with 90.0\n",
      "Current moves of: player_3 , WAITING with 90.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 30.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , COOPERATE with 90.0\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , WAITING with 90.0\n",
      "Current moves of: player_3 , WAITING with 90.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 30.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , COOPERATE with 90.0\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 81.0\n",
      "Current moves of: player_3 , WAITING with 90.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 39.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , COOPERATE with 90.0\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 81.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 48.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , COOPERATE with 90.0\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 81.0\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 48.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , COOPERATE with 90.0\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , COOPERATE with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 81.0\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_0': -0.10536051565782628, 'player_1': 0, 'player_2': -0.10536051565782628, 'player_3': -0.10536051565782628, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 48.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 90.0\n",
      "Current moves of: player_1 , WAITING with 100\n",
      "Current moves of: player_2 , WAITING with 81.0\n",
      "Current moves of: player_3 , WAITING with 81.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 48.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 90.0\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , WAITING with 81.0\n",
      "Current moves of: player_3 , WAITING with 81.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 58.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 90.0\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 81.0\n",
      "Current moves of: player_3 , WAITING with 81.0\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 58.0 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 90.0\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 72.9\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 90.0\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 72.9\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_0 , DEFECT with 90.0\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 72.9\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_0': -1.203972804325936, 'player_1': -1.309333319983762, 'player_2': -1.203972804325936, 'player_3': -1.309333319983762, 'player_4': -1.203972804325936, 'player_5': -1.203972804325936}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 72.9\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_2 , DEFECT with 81.0\n",
      "Current moves of: player_3 , COOPERATE with 72.9\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_3 , COOPERATE with 72.9\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_4': 0, 'player_5': 0}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_5': 0}\n",
      "Pool is: 66.1 , Threshold is: 200\n",
      "\n",
      "Average total reward -7.961360435560398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-7.961360435560398"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pettingzoo.utils import random_demo\n",
    "random_demo(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dilemma_v0.env()\n",
    "\n",
    "env = to_parallel(env)\n",
    "\n",
    "env = ss.pettingzoo_env_to_vec_env_v0(env)\n",
    "env = ss.concat_vec_envs_v0(env, 1, base_class='stable_baselines3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to tmp/A2C_9\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1795     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.246   |\n",
      "|    explained_variance | -0.0397  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.176    |\n",
      "|    value_loss         | 7.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1901     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0467  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.0188   |\n",
      "|    value_loss         | 6.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1917      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0283   |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 0.0097    |\n",
      "|    value_loss         | 5.86      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1959     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0108  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.00294  |\n",
      "|    value_loss         | 5.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1955     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00874 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.00216  |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1857     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00453 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.000948 |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1816     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00289 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.000529 |\n",
      "|    value_loss         | 3.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1798     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00478 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.000856 |\n",
      "|    value_loss         | 2.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1817     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00255 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.000386 |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1823     |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00125 |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.000157 |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1790      |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000983 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 0.000107  |\n",
      "|    value_loss         | 1.53      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1797      |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000697 |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 6.44e-05  |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1810     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00054 |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 4.23e-05 |\n",
      "|    value_loss         | 0.887    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1816      |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000369 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.33e-05  |\n",
      "|    value_loss         | 0.629     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1824      |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000302 |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 1.54e-05  |\n",
      "|    value_loss         | 0.419     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1831     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00021 |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 7.97e-06 |\n",
      "|    value_loss         | 0.249    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1834      |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00019  |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 5.03e-06  |\n",
      "|    value_loss         | 0.124     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1842      |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000139 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 2.02e-06  |\n",
      "|    value_loss         | 0.0415    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1844      |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000136 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 5.74e-07  |\n",
      "|    value_loss         | 0.00334   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1848      |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000125 |\n",
      "|    explained_variance | 7.57e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 3.57e-08  |\n",
      "|    value_loss         | 1.55e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1856      |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000562 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 3.49e-09  |\n",
      "|    value_loss         | 5.76e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1861      |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000562 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1865      |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000576 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1871      |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000576 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1876     |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00141 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1873     |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00141 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1813     |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00378 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1814     |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00378 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1814      |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00548  |\n",
      "|    explained_variance | 4.11e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -2.16e-06 |\n",
      "|    value_loss         | 1.31e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1810     |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00548 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1803     |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00938 |\n",
      "|    explained_variance | 2.71e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -7.7e-07 |\n",
      "|    value_loss         | 4.85e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1799      |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00434  |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -3.42e-08 |\n",
      "|    value_loss         | 5.76e-09  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1769     |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0097  |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1719     |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00709 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1643     |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00469 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1641      |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00304  |\n",
      "|    explained_variance | 5.82e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -4.36e-07 |\n",
      "|    value_loss         | 2.01e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1652     |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00426 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1652     |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00426 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1648     |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0107  |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1652      |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0124   |\n",
      "|    explained_variance | -3.52     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -8.37e-06 |\n",
      "|    value_loss         | 7.65e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1643      |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00644  |\n",
      "|    explained_variance | 0.00687   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -1.25e-07 |\n",
      "|    value_loss         | 3.06e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1646     |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00435 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1645      |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00107  |\n",
      "|    explained_variance | 0.333     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -2.38e-09 |\n",
      "|    value_loss         | 6.4e-10   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1636     |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00107 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1636     |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00115 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1645     |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00115 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1649     |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00102 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1652     |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00102 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1658     |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00134 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1636     |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00134 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1569     |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0013  |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1549      |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000557 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -4.89e-07 |\n",
      "|    value_loss         | 0.000112  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1536      |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000606 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1544      |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000606 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1552      |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000338 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1560      |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000338 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1562      |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000857 |\n",
      "|    explained_variance | 0.00264   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -3.17e-08 |\n",
      "|    value_loss         | 1.78e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1553      |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000857 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1556     |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00167 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1560     |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00223 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1558      |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00211  |\n",
      "|    explained_variance | 0.111     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -1.01e-08 |\n",
      "|    value_loss         | 2.56e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1565     |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00211 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1571     |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00277 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1578      |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00108  |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -4.82e-09 |\n",
      "|    value_loss         | 2.56e-09  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1580     |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00128 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1576     |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00204 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1580     |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00246 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1576     |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00246 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1581      |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00158  |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -1.83e-07 |\n",
      "|    value_loss         | 1.55e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1561     |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00158 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1510     |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00232 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1505     |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00232 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1505     |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00315 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1509     |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00678 |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1508     |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0155  |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1511     |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00608 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1514      |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0034   |\n",
      "|    explained_variance | 0.000432  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -6.06e-08 |\n",
      "|    value_loss         | 3.06e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1517     |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0034  |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1518     |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00511 |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1519      |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000292 |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0         |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-e326d2ea4958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             tensorboard_log='tmp/')\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/a2c/a2c.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    188\u001b[0m     ) -> \"A2C\":\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return super(A2C, self).learn(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/a2c/a2c.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# Optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# Clip grad norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C('MlpPolicy', \n",
    "            env, \n",
    "            verbose=3,\n",
    "            tensorboard_log='tmp/')\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delimma!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3), 'player_2': Discrete(3), 'player_3': Discrete(3), 'player_4': Discrete(3), 'player_5': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , WAITING with 100\n",
      "Current moves of: player_2 , WAITING with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , WAITING with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , DEFECT with 100\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , DEFECT with 100\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , WAITING with 100\n",
      "Current moves of: player_2 , WAITING with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , WAITING with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , WAITING with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , WAITING with 100\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , COOPERATE with 90.0\n",
      "Current moves of: player_5 , WAITING with 100\n",
      "rewards {'player_0': 0, 'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_0 , DEFECT with 100\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , COOPERATE with 90.0\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_0': -1.203972804325936, 'player_1': -1.309333319983762, 'player_2': -1.203972804325936, 'player_3': -1.203972804325936, 'player_4': -1.309333319983762, 'player_5': -1.203972804325936}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , COOPERATE with 90.0\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , COOPERATE with 90.0\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_1': 0, 'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "1\n",
      "Current moves of: player_2 , DEFECT with 100\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , COOPERATE with 90.0\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_2': 0, 'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_3 , DEFECT with 100\n",
      "Current moves of: player_4 , COOPERATE with 90.0\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_3': 0, 'player_4': 0, 'player_5': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_4 , COOPERATE with 90.0\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_4': 0, 'player_5': 0}\n",
      "\n",
      "1\n",
      "Current moves of: player_5 , DEFECT with 100\n",
      "rewards {'player_5': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = cdn_v0.env()\n",
    "\n",
    "#env = ss.agent_indicator_v0(env)\n",
    "rewards = []\n",
    "env.reset()\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    rewards.append(reward)\n",
    "    obs = obs\n",
    "    print(obs)\n",
    "    act = model.predict(obs)[0] if not done else None\n",
    "    env.step(act)\n",
    "    env.render()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, None)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(obs,deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-f88b7c342679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mevaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maction\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36m_get_latent\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \"\"\"\n\u001b[1;32m    551\u001b[0m         \u001b[0;31m# Preprocess the observation if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \"\"\"\n\u001b[1;32m    117\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No features extractor was set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_obs\u001b[0;34m(obs, observation_space, normalize_images)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# One hot encoding and convert to float to avoid errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDiscrete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'long'"
     ]
    }
   ],
   "source": [
    "model.policy.evaluate_actions(0,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from pettingzoo.test import parallel_api_test\n",
    "from src.environments import simple_pd_v0\n",
    "\n",
    "env = dilemma_v0.env()\n",
    "env = to_parallel(env)\n",
    "\n",
    "parallel_api_test(env, num_cycles=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dilemma_v0.env('sd')\n",
    "\n",
    "#env = ss.agent_indicator_v0(env)\n",
    "rewards = []\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 False {}\n",
      "Current state: Agent1: ANTI_SOCIAL , Agent2: ANTI_SOCIAL\n",
      "{'player_0': 1, 'player_1': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obs, reward, done, info = env.last()\n",
    "print(obs, reward, done, info)\n",
    "rewards.append(reward)\n",
    "act = model.predict(2)[0] if not done else None\n",
    "env.step(1)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0 for n in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.choice(2,  p=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-b1cebb2cf1ce>:1: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(1 - 0.1 - 0.9 - 0.1*0.9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1 - 0.1 - 0.9 - 0.1*0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09000000000000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.1 - 0.9 + 0.1*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
