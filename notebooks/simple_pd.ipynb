{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.classic import rpsls_v1\n",
    "from src.environments import simple_pd_v0\n",
    "import supersuit as ss\n",
    "from pettingzoo.utils.conversions import to_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simple_pd_v0.env()\n",
    "#env = rpsls_v1.env()\n",
    "\n",
    "env = ss.agent_indicator_v0(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: Agent1: None , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: DEFECT\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: DEFECT , Agent2: None\n",
      "Current state: Agent1: DEFECT , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Average total reward 428.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pettingzoo.utils import random_demo\n",
    "random_demo(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = to_parallel(env)\n",
    "\n",
    "env = ss.pettingzoo_env_to_vec_env_v0(env)\n",
    "env = ss.concat_vec_envs_v0(env, 4, base_class='stable_baselines3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to tmp/PPO_1\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 8353 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 1000 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4998         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 2000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010089003 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -0.693       |\n",
      "|    explained_variance   | -0.000877    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 430          |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.000582    |\n",
      "|    value_loss           | 904          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4485         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 3000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013078416 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -0.693       |\n",
      "|    explained_variance   | -0.00112     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 403          |\n",
      "|    n_updates            | 8            |\n",
      "|    policy_gradient_loss | 0.000973     |\n",
      "|    value_loss           | 934          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 4183         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 0            |\n",
      "|    total_timesteps      | 4000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027965365 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -0.692       |\n",
      "|    explained_variance   | -0.00205     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 408          |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 823          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4007        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 5000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008606773 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | -0.0019     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 512         |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | 0.00349     |\n",
      "|    value_loss           | 1.02e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3952         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 6000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029994776 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -0.689       |\n",
      "|    explained_variance   | -0.00401     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 373          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    value_loss           | 888          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-620-86939751144c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mclip_range_vf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             tensorboard_log='tmp/')\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    278\u001b[0m     ) -> \"PPO\":\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         return super(PPO, self).learn(\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;31m# Clip grad norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0mapprox_kl_divs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_log_prob\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "model = PPO('MlpPolicy', \n",
    "            env, \n",
    "            verbose=3, \n",
    "            gamma=0.99, \n",
    "            n_steps=125, \n",
    "            ent_coef=0.01, \n",
    "            learning_rate=0.00025, \n",
    "            vf_coef=0.5, \n",
    "            max_grad_norm=0.5, \n",
    "            gae_lambda=0.95, \n",
    "            n_epochs=4, \n",
    "            clip_range=0.2, \n",
    "            clip_range_vf=1,\n",
    "            tensorboard_log='tmp/')\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to tmp/A2C_5\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5921     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.315   |\n",
      "|    explained_variance | -0.0125  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.521    |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5928     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0603  |\n",
      "|    explained_variance | -0.00443 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.00733  |\n",
      "|    value_loss         | 10.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5987     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.136   |\n",
      "|    explained_variance | -0.0117  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.069    |\n",
      "|    value_loss         | 6.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5902     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.128   |\n",
      "|    explained_variance | 5.96e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0597   |\n",
      "|    value_loss         | 5.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5709     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.222   |\n",
      "|    explained_variance | 0.00431  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.704    |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5741     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.25    |\n",
      "|    explained_variance | -0.00927 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.472    |\n",
      "|    value_loss         | 6        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5753      |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.385    |\n",
      "|    explained_variance | -0.000331 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 1.97      |\n",
      "|    value_loss         | 24.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5778     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.425   |\n",
      "|    explained_variance | 0.000316 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.973    |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5739     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.442   |\n",
      "|    explained_variance | 0.000132 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.47     |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5708     |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.49    |\n",
      "|    explained_variance | 0.000142 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    value_loss         | 19.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5738     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.478   |\n",
      "|    explained_variance | -4.7e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1.17     |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5717      |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.383    |\n",
      "|    explained_variance | -2.98e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.779     |\n",
      "|    value_loss         | 9.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5736      |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.408    |\n",
      "|    explained_variance | -1.38e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 2.21      |\n",
      "|    value_loss         | 26.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5680     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.232   |\n",
      "|    explained_variance | 5.19e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.111    |\n",
      "|    value_loss         | 2.21     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5687     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.124   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.0211   |\n",
      "|    value_loss         | 0.73     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5702      |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.115    |\n",
      "|    explained_variance | -4.77e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -0.00749  |\n",
      "|    value_loss         | 3.04      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5713     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.071   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.00727  |\n",
      "|    value_loss         | 0.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5728     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0882  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.00753  |\n",
      "|    value_loss         | 0.212    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5742      |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.026    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 0.00121   |\n",
      "|    value_loss         | 0.108     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5754     |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0233  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.000626 |\n",
      "|    value_loss         | 0.0388   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5762     |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0207  |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.000196 |\n",
      "|    value_loss         | 0.0044   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5773     |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0156  |\n",
      "|    explained_variance | 0.000501 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 1.64e-06 |\n",
      "|    value_loss         | 6.77e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5779      |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0124   |\n",
      "|    explained_variance | 3.4e-06   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -3.01e-06 |\n",
      "|    value_loss         | 3.77e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5766      |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0104   |\n",
      "|    explained_variance | 1.04e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -2.89e-06 |\n",
      "|    value_loss         | 5.03e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5772      |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00306  |\n",
      "|    explained_variance | 3.4e-06   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -6.01e-07 |\n",
      "|    value_loss         | 3.77e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5783     |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 104000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0102  |\n",
      "|    explained_variance | 0.000154 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 1.04e-06 |\n",
      "|    value_loss         | 7.2e-07  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5792      |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 108000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00924  |\n",
      "|    explained_variance | 4.77e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -1.18e-05 |\n",
      "|    value_loss         | 0.000111  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5802      |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 112000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0199   |\n",
      "|    explained_variance | 4.17e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -3.93e-05 |\n",
      "|    value_loss         | 0.000201  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5807      |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 116000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00568  |\n",
      "|    explained_variance | 0.000214  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -4.55e-07 |\n",
      "|    value_loss         | 5.21e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5812      |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 120000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00645  |\n",
      "|    explained_variance | 2.69e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -1.05e-06 |\n",
      "|    value_loss         | 1.94e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5791      |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 124000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0129   |\n",
      "|    explained_variance | 0.000283  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -1.03e-06 |\n",
      "|    value_loss         | 3.9e-07   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5757      |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 128000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00733  |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -1.33e-05 |\n",
      "|    value_loss         | 0.000215  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5716      |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 132000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00278  |\n",
      "|    explained_variance | 8.12e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -5.81e-07 |\n",
      "|    value_loss         | 4.18e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5681      |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 136000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0145   |\n",
      "|    explained_variance | 8.82e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -4.33e-06 |\n",
      "|    value_loss         | 5.03e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5680      |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 140000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00539  |\n",
      "|    explained_variance | 0.00278   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -1.25e-07 |\n",
      "|    value_loss         | 4.01e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5683      |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 144000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00286  |\n",
      "|    explained_variance | 0.00278   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -6.21e-08 |\n",
      "|    value_loss         | 4.01e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5680      |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 148000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0206   |\n",
      "|    explained_variance | 1.97e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -2.02e-05 |\n",
      "|    value_loss         | 4.2e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5689     |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 152000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00624 |\n",
      "|    explained_variance | 0.000147 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 6.36e-07 |\n",
      "|    value_loss         | 8.04e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5697      |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 156000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00466  |\n",
      "|    explained_variance | 1.19e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -1.04e-06 |\n",
      "|    value_loss         | 4.38e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5704      |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 160000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00742  |\n",
      "|    explained_variance | 0.000164  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -7.48e-07 |\n",
      "|    value_loss         | 6.77e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5713     |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 164000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0181  |\n",
      "|    explained_variance | 1.85e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.142   |\n",
      "|    value_loss         | 0.842    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5718      |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 168000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00212  |\n",
      "|    explained_variance | 2.21e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -8.27e-07 |\n",
      "|    value_loss         | 1.57e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5712      |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 172000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000421 |\n",
      "|    explained_variance | 2.65e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -1.03e-07 |\n",
      "|    value_loss         | 9.09e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5710     |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 176000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00469 |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -5.8e-06 |\n",
      "|    value_loss         | 0.000134 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5710      |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 180000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00364  |\n",
      "|    explained_variance | 5.26e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -9.88e-07 |\n",
      "|    value_loss         | 6.21e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5709      |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 184000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0169   |\n",
      "|    explained_variance | 0.000131  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -4.55e-06 |\n",
      "|    value_loss         | 3.58e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5709     |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 188000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0147  |\n",
      "|    explained_variance | 7.33e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.301   |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5694     |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00643 |\n",
      "|    explained_variance | 0.000401 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 6.96e-07 |\n",
      "|    value_loss         | 9.46e-07 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5690      |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 196000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00805  |\n",
      "|    explained_variance | 6.75e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -1.88e-06 |\n",
      "|    value_loss         | 3.58e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5676     |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00121 |\n",
      "|    explained_variance | 0.000315 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 1.21e-07 |\n",
      "|    value_loss         | 1.2e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5647     |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 204000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00175 |\n",
      "|    explained_variance | 0.00138  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -4.2e-08 |\n",
      "|    value_loss         | 6.2e-08  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5617     |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 208000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0031  |\n",
      "|    explained_variance | 0.00102  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 3.06e-07 |\n",
      "|    value_loss         | 9.46e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5611      |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 212000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00182  |\n",
      "|    explained_variance | 6.32e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.05e-07 |\n",
      "|    value_loss         | 1.41e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5617      |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 216000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000715 |\n",
      "|    explained_variance | 2.66e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -1.32e-07 |\n",
      "|    value_loss         | 4.18e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5621      |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 220000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.89e-05 |\n",
      "|    explained_variance | 0.00104   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -2.91e-09 |\n",
      "|    value_loss         | 2e-07     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5623      |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 224000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00119  |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -5.33e-09 |\n",
      "|    value_loss         | 2.56e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5625     |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 228000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00926 |\n",
      "|    explained_variance | 0.000125 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 1.06e-06 |\n",
      "|    value_loss         | 9.46e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5630      |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 232000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00318  |\n",
      "|    explained_variance | 5.87e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -4.65e-07 |\n",
      "|    value_loss         | 1.88e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5634     |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 236000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0128  |\n",
      "|    explained_variance | 0.000347 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 1.65e-06 |\n",
      "|    value_loss         | 1.1e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5638     |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00619 |\n",
      "|    explained_variance | 1.7e-05  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 6.01e-07 |\n",
      "|    value_loss         | 7.63e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5641      |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 244000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00037  |\n",
      "|    explained_variance | 6.44e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -1.56e-07 |\n",
      "|    value_loss         | 2.53e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5645      |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 248000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0157   |\n",
      "|    explained_variance | 0.00171   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -5.09e-07 |\n",
      "|    value_loss         | 5e-08     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5647      |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 252000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000638 |\n",
      "|    explained_variance | 0.000164  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -1.17e-07 |\n",
      "|    value_loss         | 4.49e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5647      |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 256000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000406 |\n",
      "|    explained_variance | 0.000476  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -9.05e-08 |\n",
      "|    value_loss         | 6.85e-06  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5650     |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00229 |\n",
      "|    explained_variance | 0.00417  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 2.67e-07 |\n",
      "|    value_loss         | 1.26e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5651      |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 264000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000485 |\n",
      "|    explained_variance | 0.00722   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 3.37e-08  |\n",
      "|    value_loss         | 7.2e-07   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5651      |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 268000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000185 |\n",
      "|    explained_variance | 0.00354   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 1.56e-08  |\n",
      "|    value_loss         | 1.2e-06   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5657     |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 272000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0027  |\n",
      "|    explained_variance | 0.00216  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 3.35e-07 |\n",
      "|    value_loss         | 1.37e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5658      |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 276000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0565   |\n",
      "|    explained_variance | 2.11e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -0.000149 |\n",
      "|    value_loss         | 0.000247  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5662      |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 280000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00512  |\n",
      "|    explained_variance | 0.00424   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -8.44e-07 |\n",
      "|    value_loss         | 1.94e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5663      |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 284000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0138   |\n",
      "|    explained_variance | 0.792     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -9.49e-08 |\n",
      "|    value_loss         | 2.56e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5666      |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 288000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000756 |\n",
      "|    explained_variance | 0.000344  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -2.21e-07 |\n",
      "|    value_loss         | 1.17e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5659      |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 292000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000805 |\n",
      "|    explained_variance | 0.471     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -5.54e-09 |\n",
      "|    value_loss         | 5.76e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5649      |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 296000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000158 |\n",
      "|    explained_variance | 0.000273  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -3.98e-08 |\n",
      "|    value_loss         | 1.08e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5602      |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 300000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00151  |\n",
      "|    explained_variance | 0.00148   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -2.15e-07 |\n",
      "|    value_loss         | 2.01e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5556     |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 304000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00336 |\n",
      "|    explained_variance | 0.115    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -4.4e-08 |\n",
      "|    value_loss         | 1.6e-08  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5529     |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 308000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00955 |\n",
      "|    explained_variance | 0.00346  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 9.06e-07 |\n",
      "|    value_loss         | 5.97e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5527     |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 312000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00163 |\n",
      "|    explained_variance | 0.00195  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 1.67e-07 |\n",
      "|    value_loss         | 1.05e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5525     |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 316000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00224 |\n",
      "|    explained_variance | 0.00494  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 3.04e-07 |\n",
      "|    value_loss         | 1.68e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5508     |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 320000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00221 |\n",
      "|    explained_variance | 0.0082   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 2.27e-07 |\n",
      "|    value_loss         | 9.96e-07 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5508      |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 324000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000593 |\n",
      "|    explained_variance | 7.37e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -3.15e-07 |\n",
      "|    value_loss         | 4e-05     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5481     |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 328000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00011 |\n",
      "|    explained_variance | 0.0385   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 2.25e-09 |\n",
      "|    value_loss         | 7.52e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5477      |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 332000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00657  |\n",
      "|    explained_variance | 0.000101  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -0.000186 |\n",
      "|    value_loss         | 88.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5474     |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 336000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00502 |\n",
      "|    explained_variance | 0.000451 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.00195  |\n",
      "|    value_loss         | 87.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5453     |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 340000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00225 |\n",
      "|    explained_variance | 0.15     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 0.00241  |\n",
      "|    value_loss         | 86.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5450     |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 344000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00266 |\n",
      "|    explained_variance | 0.00224  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 0.00163  |\n",
      "|    value_loss         | 35.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5436     |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 348000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00095 |\n",
      "|    explained_variance | 0.000158 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 0.000502 |\n",
      "|    value_loss         | 33.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5428      |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 352000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000387 |\n",
      "|    explained_variance | 3.47e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 0.00018   |\n",
      "|    value_loss         | 32.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5425      |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 356000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000204 |\n",
      "|    explained_variance | 1.1e-05   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 8.6e-05   |\n",
      "|    value_loss         | 30.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5411      |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 360000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000118 |\n",
      "|    explained_variance | 3.93e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 4.66e-05  |\n",
      "|    value_loss         | 29.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5398     |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 364000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.1e-05 |\n",
      "|    explained_variance | 1.55e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 2.61e-05 |\n",
      "|    value_loss         | 27.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5398      |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 368000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.39e-05 |\n",
      "|    explained_variance | 5.96e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 1.44e-05  |\n",
      "|    value_loss         | 26.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5402      |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 372000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.78e-05 |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 8.63e-06  |\n",
      "|    value_loss         | 24.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5385      |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 376000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.79e-05 |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 5.25e-06  |\n",
      "|    value_loss         | 23.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5380      |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 380000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.15e-05 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 3.06e-06  |\n",
      "|    value_loss         | 22.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5379      |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 384000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.89e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 1.98e-06  |\n",
      "|    value_loss         | 21.1      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5381     |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 388000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.5e-06 |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 9.63e-07 |\n",
      "|    value_loss         | 19.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5387      |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 392000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.84e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 9.34e-07  |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5392      |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 396000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.69e-06 |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 17.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5397      |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 400000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.15e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 16.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5401      |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 404000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.71e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5406      |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 408000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37e-06 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 14.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5410      |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 412000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.11e-06 |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 13.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5414      |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 416000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.11e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5419      |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 420000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.63e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 11.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5424      |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 424000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.51e-07 |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 10.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5427      |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 428000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64e-07 |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 9.69      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5432      |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 432000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.95e-07 |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 8.88      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5435     |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 436000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.4e-07 |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 8.1      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5439      |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 440000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.94e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 7.35      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5443      |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 444000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.56e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5446      |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 448000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.24e-07 |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5451      |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 452000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96e-07 |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5437      |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 456000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.72e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.73      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5435      |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 460000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.51e-07 |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5437      |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 464000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.32e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5440      |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 468000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.15e-07 |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.14      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5444     |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 472000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2e-07   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5448      |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 476000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.86e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5451      |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 480000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.73e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.88      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5455      |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 484000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.61e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.53      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5457      |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 488000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.49e-07 |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.21      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5460      |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 492000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.39e-07 |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.936     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5461      |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 496000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.28e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.694     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5464      |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 500000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.18e-07 |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.489     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5465      |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 504000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.08e-07 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.319     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5460      |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 508000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.78e-08 |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.185     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5463      |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 512000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.69e-08 |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.0879    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5466      |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 516000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.41e-08 |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.0263    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5469      |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 520000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.57e-08 |\n",
      "|    explained_variance | 2.44e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.0014    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5471     |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 524000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.1e-08 |\n",
      "|    explained_variance | 9.18e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 2.29e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5458      |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 528000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.27e-08 |\n",
      "|    explained_variance | 0.000404  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.39e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5453      |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 532000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.72e-08 |\n",
      "|    explained_variance | 7.35e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.85e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5449      |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 536000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.34e-08 |\n",
      "|    explained_variance | 0.00782   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.96e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5437      |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 540000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.05e-08 |\n",
      "|    explained_variance | 0.00131   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.44e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5430      |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 544000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.82e-08 |\n",
      "|    explained_variance | 0.000949  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.44e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5423      |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 548000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.64e-08 |\n",
      "|    explained_variance | 0.000949  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.44e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 5415     |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 552000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5e-08 |\n",
      "|    explained_variance | 0.00113  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.2e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 5413      |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 556000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.38e-08 |\n",
      "|    explained_variance | 0.00504   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.2e-06   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-653-e326d2ea4958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             tensorboard_log='tmp/')\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/a2c/a2c.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    188\u001b[0m     ) -> \"A2C\":\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return super(A2C, self).learn(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/a2c/a2c.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mexplained_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplained_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_updates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/utils.py\u001b[0m in \u001b[0;36mexplained_variance\u001b[0;34m(y_pred, y_true)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \"\"\"\n\u001b[1;32m     57\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mvar_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvar_y\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvar_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   3700\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3702\u001b[0;31m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0m\u001b[1;32m   3703\u001b[0m                          **kwargs)\n\u001b[1;32m   3704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;31m# Note that if dtype is not of inexact type then arraymean will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# not be either.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0marrmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;31m# The shape of rcount has to match arrmean to not change the shape of out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;31m# in broadcasting. Otherwise, it cannot be stored back to arrmean.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C('MlpPolicy', \n",
    "            env, \n",
    "            verbose=3,\n",
    "            tensorboard_log='tmp/')\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n",
      "Current state: Agent1: COOPERATE , Agent2: None\n",
      "Current state: Agent1: COOPERATE , Agent2: COOPERATE\n"
     ]
    }
   ],
   "source": [
    "env = env = simple_pd_v0.env()\n",
    "\n",
    "env = ss.agent_indicator_v0(env)\n",
    "\n",
    "env.reset()\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    act = model.predict(obs)[0] if not done else None\n",
    "    env.step(act)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.test import parallel_api_test\n",
    "env = simple_pd_v0.env()\n",
    "env = to_parallel(env)\n",
    "\n",
    "parallel_api_test(env, num_cycles=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
