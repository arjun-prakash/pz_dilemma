{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.environments import centipede_v0\n",
    "import supersuit as ss\n",
    "from pettingzoo.utils.conversions import to_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n"
     ]
    }
   ],
   "source": [
    "env = centipede_v0.env()\n",
    "#env = rpsls_v1.env()\n",
    "\n",
    "\n",
    "#env = ss.agent_indicator_v0(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current moves of: player_0 , NONE\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "Current moves of: player_0 , COOPERATE\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "Current moves of: player_0 , COOPERATE\n",
      "Current moves of: player_1 , COOPERATE\n",
      "rewards {'player_0': 1, 'player_1': 1}\n",
      "\n",
      "Current moves of: player_0 , COOPERATE\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "Current moves of: player_0 , COOPERATE\n",
      "Current moves of: player_1 , COOPERATE\n",
      "rewards {'player_0': 1, 'player_1': 1}\n",
      "\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , COOPERATE\n",
      "rewards {'player_0': 22, 'player_1': 2}\n",
      "\n",
      "Current moves of: player_1 , COOPERATE\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "Average total reward 28.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pettingzoo.utils import random_demo\n",
    "random_demo(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n"
     ]
    }
   ],
   "source": [
    "env = centipede_v0.env()\n",
    "\n",
    "env = to_parallel(env)\n",
    "\n",
    "env = ss.pettingzoo_env_to_vec_env_v0(env)\n",
    "env = ss.concat_vec_envs_v0(env, 1, base_class='stable_baselines3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to tmp/PPO_23\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 4032 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2323        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | -0.08199037 |\n",
      "|    clip_fraction        | 0.595       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | -0.00127    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48          |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0973     |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2030         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.035970215 |\n",
      "|    clip_fraction        | 0.657        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.61        |\n",
      "|    explained_variance   | 0.00386      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.5         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.086       |\n",
      "|    value_loss           | 97.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1915        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008100154 |\n",
      "|    clip_fraction        | 0.536       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | 0.0016      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0674     |\n",
      "|    value_loss           | 98.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1849       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16122013 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 4.5e-05    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 49.6       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 99.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1811         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031438954 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0345      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1784          |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030870718 |\n",
      "|    clip_fraction        | 0.00479       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0244       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 49.1          |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00098      |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1764         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006038404 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0145      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.2         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000723    |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1741         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001015889 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00939     |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000322    |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1724         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.010286e-05 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00694     |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000224    |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1710         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002643945 |\n",
      "|    clip_fraction        | 0.00129      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00519     |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50           |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.000273    |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1698          |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025507325 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00371      |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 50.1          |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000238     |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1689          |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 31            |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8869603e-05 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00303      |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 50.6          |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -8.56e-05     |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1681     |\n",
      "|    iterations           | 14       |\n",
      "|    time_elapsed         | 34       |\n",
      "|    total_timesteps      | 57344    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00295 |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 50.9     |\n",
      "|    n_updates            | 130      |\n",
      "|    policy_gradient_loss | 2.08e-10 |\n",
      "|    value_loss           | 100      |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1673          |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015087076 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00181      |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 49.9          |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -8.89e-05     |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1667     |\n",
      "|    iterations           | 16       |\n",
      "|    time_elapsed         | 39       |\n",
      "|    total_timesteps      | 65536    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.0017  |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 50       |\n",
      "|    n_updates            | 150      |\n",
      "|    policy_gradient_loss | 5.92e-10 |\n",
      "|    value_loss           | 100      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1661      |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0017   |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 49.9      |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -1.15e-10 |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1656          |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 44            |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032483507 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000798     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 50.1          |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -9.17e-05     |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1652      |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000772 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 50        |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -1.5e-09  |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1648      |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000772 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 50        |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | 1.03e-09  |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1645      |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000772 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 50        |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | 4.71e-10  |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1642      |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000772 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 50.1      |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 1.35e-10  |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1639          |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 57            |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028800988 |\n",
      "|    clip_fraction        | 0.000708      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000539     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 50            |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000145     |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1633      |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000524 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 49.7      |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | 1.62e-10  |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1629      |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 102400    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000524 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 50        |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -2.47e-11 |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1626      |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 106496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000524 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 49.8      |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -1.25e-09 |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1623      |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 110592    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000524 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 49.9      |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -7.39e-10 |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1613      |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 114688    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.000524 |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 50.2      |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -2.42e-10 |\n",
      "|    value_loss           | 100       |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1612          |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 73            |\n",
      "|    total_timesteps      | 118784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020460761 |\n",
      "|    clip_fraction        | 0.00022       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00023      |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 50            |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -4.24e-05     |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1601          |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 76            |\n",
      "|    total_timesteps      | 122880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017266627 |\n",
      "|    clip_fraction        | 0.00022       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000121     |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 50            |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -4.26e-05     |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1531     |\n",
      "|    iterations           | 31       |\n",
      "|    time_elapsed         | 82       |\n",
      "|    total_timesteps      | 126976   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00011 |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 50       |\n",
      "|    n_updates            | 300      |\n",
      "|    policy_gradient_loss | 8.27e-10 |\n",
      "|    value_loss           | 100      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1528     |\n",
      "|    iterations           | 32       |\n",
      "|    time_elapsed         | 85       |\n",
      "|    total_timesteps      | 131072   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.00011 |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 50       |\n",
      "|    n_updates            | 310      |\n",
      "|    policy_gradient_loss | 1.53e-09 |\n",
      "|    value_loss           | 100      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-8b405c97c953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtensorboard_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tmp/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    278\u001b[0m     ) -> \"PPO\":\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         return super(PPO, self).learn(\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mentropy_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "\n",
    "model = PPO('MlpPolicy', \n",
    "            env, \n",
    "            verbose=3,\n",
    "            tensorboard_log='tmp/',\n",
    "            )\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n",
      "Centipede!\n",
      "{'player_0': Discrete(3), 'player_1': Discrete(3)}\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , NONE\n",
      "rewards {'player_0': 0, 'player_1': 0}\n",
      "\n",
      "2\n",
      "Current moves of: player_0 , DEFECT\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_0': 20, 'player_1': 0}\n",
      "\n",
      "0\n",
      "Current moves of: player_1 , DEFECT\n",
      "rewards {'player_1': 0}\n",
      "\n",
      "0\n",
      "rewards {}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 20, 0]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    env = centipede_v0.env()\n",
    "\n",
    "    #env = ss.agent_indicator_v0(env)\n",
    "    rewards = []\n",
    "    env.reset()\n",
    "    for agent in env.agent_iter():\n",
    "        obs, reward, done, info = env.last()\n",
    "        rewards.append(reward)\n",
    "        obs = obs\n",
    "        print(obs)\n",
    "        act = model.predict(obs)[0] if not done else None\n",
    "        env.step(act)\n",
    "        env.render()\n",
    "    \n",
    "    r.append(len(rewards))\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/anaconda3/envs/rlenv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/arjun/anaconda3/envs/rlenv/lib/python3.8/site-packages/seaborn/distributions.py:306: UserWarning: Dataset has 0 variance; skipping density estimate.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/anaconda3/envs/rlenv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from pettingzoo.test import parallel_api_test\n",
    "from src.environments import simple_pd_v0\n",
    "\n",
    "env = dilemma_v0.env()\n",
    "env = to_parallel(env)\n",
    "\n",
    "parallel_api_test(env, num_cycles=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dilemma_v0.env('sd')\n",
    "\n",
    "#env = ss.agent_indicator_v0(env)\n",
    "rewards = []\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 False {}\n",
      "Current state: Agent1: ANTI_SOCIAL , Agent2: ANTI_SOCIAL\n",
      "{'player_0': 1, 'player_1': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obs, reward, done, info = env.last()\n",
    "print(obs, reward, done, info)\n",
    "rewards.append(reward)\n",
    "act = model.predict(2)[0] if not done else None\n",
    "env.step(1)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0 for n in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.choice(2,  p=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-b1cebb2cf1ce>:1: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(1 - 0.1 - 0.9 - 0.1*0.9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1 - 0.1 - 0.9 - 0.1*0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09000000000000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.1 - 0.9 + 0.1*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
