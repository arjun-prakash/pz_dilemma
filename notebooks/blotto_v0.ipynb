{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.classic import rpsls\n",
    "from src.environments import blotto_v0\n",
    "import supersuit as ss\n",
    "from pettingzoo.utils.conversions import to_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lk\n"
     ]
    }
   ],
   "source": [
    "env = blotto_v0.env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "a = [0,0,1,0,0]\n",
    "m, _ = stats.mode(a)\n",
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: Agent1: [0 0 0 0 0 0 0 0 0 0] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [67 39 43 16 67 13 21 70 57 56] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [67 39 43 16 67 13 21 70 57 56] , Agent2: [31 98 41 62 60 37 91 50 75 57]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 45 35 51 87 37 63 29 37 58] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 45 35 51 87 37 63 29 37 58] , Agent2: [87 94 46 13 39 56 95  2 27  2]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 17 93 18 44  2 77  9 56 75] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 17 93 18 44  2 77  9 56 75] , Agent2: [52 88 38 86 83 20 87  4 79 27]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 30 98 98 85 43 58 71  5  7] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 30 98 98 85 43 58 71  5  7] , Agent2: [13  1 46 29 43 38 17 51 10 16]\n",
      "winner is:  0\n",
      "Current state: Agent1: [94 50  1 88  7 43 80 99 33 15] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [94 50  1 88  7 43 80 99 33 15] , Agent2: [75 55 13 91 85 51 78 54 55 89]\n",
      "winner is:  0\n",
      "Current state: Agent1: [57 58  8 17 78 66 89 94 10 65] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [57 58  8 17 78 66 89 94 10 65] , Agent2: [50  1 84 51 75 94 61 91 48 74]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44 49 51  8 65 47 23 57 15 19] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44 49 51  8 65 47 23 57 15 19] , Agent2: [46 41 11 39 45 11 18  5 68 91]\n",
      "winner is:  0\n",
      "Current state: Agent1: [67 97 64 32 83 27 51 89 39 50] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [67 97 64 32 83 27 51 89 39 50] , Agent2: [12 93 63 46 45 91 24  9  6 72]\n",
      "winner is:  0\n",
      "Current state: Agent1: [95 16 80 36  7 78 99 68 58 73] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [95 16 80 36  7 78 99 68 58 73] , Agent2: [71 38 50 42 92 11 63 19 78 90]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 33  1 87 18 12 21 92 47 31] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 33  1 87 18 12 21 92 47 31] , Agent2: [20 31  3 12 34 41 21 76 71 47]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 96 57 72 27 92 61  4 87 59] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 96 57 72 27 92 61  4 87 59] , Agent2: [77 19 96 16 40  5 76 52  0 35]\n",
      "winner is:  0\n",
      "Current state: Agent1: [45 66 96 29 52 46 45 11 77 66] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [45 66 96 29 52 46 45 11 77 66] , Agent2: [94 13 64 78 33 38 31 53 53 59]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 89 63 86 76 56 45 42 22 48] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 89 63 86 76 56 45 42 22 48] , Agent2: [ 2 45 69 79 49 14 58 52 92 77]\n",
      "winner is:  0\n",
      "Current state: Agent1: [49 71 65 19 91 18 85 30 78 89] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [49 71 65 19 91 18 85 30 78 89] , Agent2: [70 98 89  8 95 29 90 70 87 98]\n",
      "winner is:  0\n",
      "Current state: Agent1: [86 93 40  0 68  5 46 59 36  3] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [86 93 40  0 68  5 46 59 36  3] , Agent2: [97 77 48 29 30 88 24 50 42  1]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 84 94 37 76 40 21 25 33 99] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 84 94 37 76 40 21 25 33 99] , Agent2: [35 31 30 84 94 70 56 93 87  1]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 35 28 55 48 81 50 94 29 80] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 35 28 55 48 81 50 94 29 80] , Agent2: [88  9  2 56 24 60 58 30 49 44]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 89 84 73 17 24 56 74 59 95] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 89 84 73 17 24 56 74 59 95] , Agent2: [97  9 56 81 35 58 69 16 23 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [33  6 24 45 68 94 80 88 48 99] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [33  6 24 45 68 94 80 88 48 99] , Agent2: [96  2 56 94 45 99  1 88 45 56]\n",
      "winner is:  0\n",
      "Current state: Agent1: [84 19 87 73 15 30  0 68  9 49] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [84 19 87 73 15 30  0 68  9 49] , Agent2: [52 57 99 14 90 65 40 81 77 56]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 25 60 71 61 81 71  0  1  8] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 25 60 71 61 81 71  0  1  8] , Agent2: [41 45 36  3 88 83 20 26 20 86]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 0 98 59 90 31 80 19 41 83 31] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 0 98 59 90 31 80 19 41 83 31] , Agent2: [21 69 74 26 38 65 36 36 87 33]\n",
      "winner is:  0\n",
      "Current state: Agent1: [92 78 49 78 96 56 17 20 60 76] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [92 78 49 78 96 56 17 20 60 76] , Agent2: [ 1 61 82 61 20  4 16  1 53 28]\n",
      "winner is:  0\n",
      "Current state: Agent1: [93 79 26 74  5 25 68 61 95  7] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [93 79 26 74  5 25 68 61 95  7] , Agent2: [61 32 12 91 33 96 11 12 51 52]\n",
      "winner is:  0\n",
      "Current state: Agent1: [95 98 56 66  6 33 31 87 97 58] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [95 98 56 66  6 33 31 87 97 58] , Agent2: [98 23 95 84 58 92 56 61 85 76]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 7 68 30 53 56 26 24 66 20 61] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 7 68 30 53 56 26 24 66 20 61] , Agent2: [90 58 38 54 57 70 29 26 15 28]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44 17 11 57 46 36  2 74 78 60] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44 17 11 57 46 36  2 74 78 60] , Agent2: [78 12 23 81 62 47 41 98 45 53]\n",
      "winner is:  0\n",
      "Current state: Agent1: [24  2 64 94 75 58 90 28 26 32] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [24  2 64 94 75 58 90 28 26 32] , Agent2: [54  6 82 59 88 93  4 14 21 87]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 0 94 77 24 44 91 96 89 54  7] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 0 94 77 24 44 91 96 89 54  7] , Agent2: [12  7 74 20 64 51 25 48 27 93]\n",
      "winner is:  0\n",
      "Current state: Agent1: [40 87 42 22 30 54 51 16 48  3] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [40 87 42 22 30 54 51 16 48  3] , Agent2: [13 61 55 89 93 44 88 70  7 60]\n",
      "winner is:  0\n",
      "Current state: Agent1: [98 55 54  8 59 65 48 10 78 45] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [98 55 54  8 59 65 48 10 78 45] , Agent2: [ 2  7 48  2 21 90 76 88 84 33]\n",
      "winner is:  0\n",
      "Current state: Agent1: [46 75  4 84 23 68  7 31 66 54] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [46 75  4 84 23 68  7 31 66 54] , Agent2: [91 78 99 86 85 31 47 99 16 89]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 42 99 37 12 88 82 82 10 68] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 42 99 37 12 88 82 82 10 68] , Agent2: [19 56 42 96  2  5 35 50 75 64]\n",
      "winner is:  0\n",
      "Current state: Agent1: [52 22 11 26 54 34 85 93 44 12] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [52 22 11 26 54 34 85 93 44 12] , Agent2: [10 37 83 96 99 19 54 40 88 94]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 21 24 66 16 41 43 10 93 89] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 21 24 66 16 41 43 10 93 89] , Agent2: [93 83 30 74  2 50 20 38 39 86]\n",
      "winner is:  0\n",
      "Current state: Agent1: [21 88 65 40 94 43 39 72 57 51] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [21 88 65 40 94 43 39 72 57 51] , Agent2: [15 66 83 11 43 43 79 13 57 92]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 19 71 32  3 17 45 71 81 98] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 19 71 32  3 17 45 71 81 98] , Agent2: [34 65 98 33 25 31 29 11 98 38]\n",
      "winner is:  0\n",
      "Current state: Agent1: [68 56 93 17 73 66 89 13 67 45] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [68 56 93 17 73 66 89 13 67 45] , Agent2: [66 84 99 67 90 26 66 92 54 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 99 47 29 44 98 39 56 76 36] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 99 47 29 44 98 39 56 76 36] , Agent2: [ 2 92 93 15 30 79 38 23 79 76]\n",
      "winner is:  0\n",
      "Current state: Agent1: [41 61 27 46 16 77 63 69 27 49] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [41 61 27 46 16 77 63 69 27 49] , Agent2: [64 92 23 24 47 99 98 60 90  7]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 54 26 54  8 69 66 20 12 44] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 54 26 54  8 69 66 20 12 44] , Agent2: [54  5 63 67 26 25 74 96 36 58]\n",
      "winner is:  0\n",
      "Current state: Agent1: [74 22 93 59 75  4 48 81 12 23] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [74 22 93 59 75  4 48 81 12 23] , Agent2: [25 67 76 26 18 45  1 23 53 55]\n",
      "winner is:  0\n",
      "Current state: Agent1: [55 89 54 51 97  4 31 35 50 80] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [55 89 54 51 97  4 31 35 50 80] , Agent2: [40 15 51  5 73 74 66 18 56 74]\n",
      "winner is:  0\n",
      "Current state: Agent1: [26 74 32 70 48 45 79 64 68 64] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [26 74 32 70 48 45 79 64 68 64] , Agent2: [12 34 72 89 53 44 75 89 34 60]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5  3  7 71 27 99 45 54 96 29] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5  3  7 71 27 99 45 54 96 29] , Agent2: [42 41 24 41 43  2 14 13  6 25]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 47 54 88 64 73 33  5 56 15] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 47 54 88 64 73 33  5 56 15] , Agent2: [30 91 64 84 41 59 58 78  0 31]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 9 48  6  1 32 32 49 90  4 94] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 9 48  6  1 32 32 49 90  4 94] , Agent2: [37 93  2 41 21 64 82 80 24 50]\n",
      "winner is:  0\n",
      "Current state: Agent1: [96 88 11 84 68 13 11 50  8 73] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [96 88 11 84 68 13 11 50  8 73] , Agent2: [ 5 85 63 80 75 73  3 50 93 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [32 87  5 90 86 91 70 76 95 67] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [32 87  5 90 86 91 70 76 95 67] , Agent2: [84 25 39 25 92  8 49  4 79 15]\n",
      "winner is:  0\n",
      "Current state: Agent1: [29 68 32 30 40 94 76 31 69 97] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [29 68 32 30 40 94 76 31 69 97] , Agent2: [92 28 81 54 99 94 99 54 35 65]\n",
      "winner is:  0\n",
      "Current state: Agent1: [46 99 53 80 82 52 76 69 31 84] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [46 99 53 80 82 52 76 69 31 84] , Agent2: [37 99  7 61 13 72 45 54  5 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [79  8 19  3  9 63 74 75 27 73] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [79  8 19  3  9 63 74 75 27 73] , Agent2: [72 82 11 37 74 72 20 87  5 67]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 31 19 62 49  2  1 15 32  9] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 31 19 62 49  2  1 15 32  9] , Agent2: [73 63 60 91 63  4 21 38 39 47]\n",
      "winner is:  0\n",
      "Current state: Agent1: [97 55 75 42 66 92 98 48 68 48] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [97 55 75 42 66 92 98 48 68 48] , Agent2: [82 48 70 34 10 60 70 39 85 51]\n",
      "winner is:  0\n",
      "Current state: Agent1: [78 26 28 71 91 66  8 19 93 15] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [78 26 28 71 91 66  8 19 93 15] , Agent2: [22 38 96 99  6 55 94 21 33 91]\n",
      "winner is:  0\n",
      "Current state: Agent1: [74 56 87 18  3 81 21  9 62  7] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [74 56 87 18  3 81 21  9 62  7] , Agent2: [33 58 13 44 66 25 18  9 31 27]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 65 83  6 19 58  4 42 77 36] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 65 83  6 19 58  4 42 77 36] , Agent2: [34 13 73 28 51 51 32 22 87 29]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44  1  2 66  1 97 78 52 87 95] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44  1  2 66  1 97 78 52 87 95] , Agent2: [47 64 22 63 83  2 65 80 60 16]\n",
      "winner is:  0\n",
      "Current state: Agent1: [97 48 82 40 63 94 52 44 10 69] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [97 48 82 40 63 94 52 44 10 69] , Agent2: [34 47 25 88 72 12 95 80 63 31]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 85 80  6 88 47 82 33 70 95] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 85 80  6 88 47 82 33 70 95] , Agent2: [45 95  9 57 30 62 36 31  1 55]\n",
      "winner is:  0\n",
      "Current state: Agent1: [32 87 29 17 29 16  7 70 18 63] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [32 87 29 17 29 16  7 70 18 63] , Agent2: [35 61 62 89  8 47 98 61 66 38]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 21 99 65  3 76 31 47 17 49] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 21 99 65  3 76 31 47 17 49] , Agent2: [74 78 54 77 16 71 60 60 67 55]\n",
      "winner is:  0\n",
      "Current state: Agent1: [63 22 30 23 83 51 14  6 98 54] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [63 22 30 23 83 51 14  6 98 54] , Agent2: [25  1  5 19 80 65  3 45 49 78]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 58 85 97 98 40 76 68 13 56] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 58 85 97 98 40 76 68 13 56] , Agent2: [33 66 41 38 66 94 51 36  4 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [21 72 44 47 16 59  0  8 28 78] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [21 72 44 47 16 59  0  8 28 78] , Agent2: [32 90 98 93 23 13 30 48 36 15]\n",
      "winner is:  0\n",
      "Current state: Agent1: [15 79 21 51  2 65  5  9 64 97] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [15 79 21 51  2 65  5  9 64 97] , Agent2: [29 98 70 73 12 57 63 35 38 58]\n",
      "winner is:  0\n",
      "Current state: Agent1: [34 52 23 50 84 95 49 64 27 41] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [34 52 23 50 84 95 49 64 27 41] , Agent2: [44 93  9 57 55  8 64  2 73 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 67 36 53 58 78 85  3 76 87] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 67 36 53 58 78 85  3 76 87] , Agent2: [38 56 61 30 11 49 72 24 75 82]\n",
      "winner is:  0\n",
      "Current state: Agent1: [81 19 26  0 81 53 82 53 71 34] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [81 19 26  0 81 53 82 53 71 34] , Agent2: [93 71 20 44 38 69 77 79  0 23]\n",
      "winner is:  0\n",
      "Current state: Agent1: [24 74 57 81 94 97 53 90 93 95] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [24 74 57 81 94 97 53 90 93 95] , Agent2: [53 71 33 73 95 73 77 72 73 19]\n",
      "winner is:  0\n",
      "Current state: Agent1: [95 59 97 11 49 84 41 21 68 73] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [95 59 97 11 49 84 41 21 68 73] , Agent2: [91 41 43 67  2 58 53 56 57 38]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 95 49 69 16 76 68 15 69 76] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 95 49 69 16 76 68 15 69 76] , Agent2: [19 76 17 38 24  7 28 27 44 68]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 8 29 15 24 40 69 83 86  2 46] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 8 29 15 24 40 69 83 86  2 46] , Agent2: [12 41 39 28 39 12 63  0 25 54]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 14 81 79 44 82 31  0 13 11] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 14 81 79 44 82 31  0 13 11] , Agent2: [11 30 27 42  5 11 25 79 78 50]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 74 87 10 75 27 55 15 49 73] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 74 87 10 75 27 55 15 49 73] , Agent2: [59 88 87 98 68 13 97 99 37 24]\n",
      "winner is:  0\n",
      "Current state: Agent1: [35 76 46 50 17 10 83 97 71 86] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [35 76 46 50 17 10 83 97 71 86] , Agent2: [94 56 50 29 19 13 68 25 39 55]\n",
      "winner is:  0\n",
      "Current state: Agent1: [63 96 33 20 18 97 94 88 78 51] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [63 96 33 20 18 97 94 88 78 51] , Agent2: [97 53 78 25 47 42 50 33 40  2]\n",
      "winner is:  0\n",
      "Current state: Agent1: [83 80 97  9 28 92 97 93 61 80] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [83 80 97  9 28 92 97 93 61 80] , Agent2: [27 22 42 90  3 38 27 80 49 15]\n",
      "winner is:  0\n",
      "Current state: Agent1: [25 82 65 38 71 24 33 63  4 77] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [25 82 65 38 71 24 33 63  4 77] , Agent2: [29 67 81 93 25 48 41 84 61 70]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 70 71 35 77 40 42  4 72 42] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 70 71 35 77 40 42  4 72 42] , Agent2: [34 29 87  9  6 72 93 28  7 28]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 81 68 94 51 15 62 70 56 76] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 81 68 94 51 15 62 70 56 76] , Agent2: [47 93  9 60 20 39 29 99 65 17]\n",
      "winner is:  0\n",
      "Current state: Agent1: [76  6 30 83 23 35 39 94 49 71] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [76  6 30 83 23 35 39 94 49 71] , Agent2: [80 94 13 67 81 46 16 31 93 76]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 51 64 61  4 92 58  9 52 16] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 51 64 61  4 92 58  9 52 16] , Agent2: [56 41 47 48 61 52 10 26 70 14]\n",
      "winner is:  0\n",
      "Current state: Agent1: [53 85 32 83 76 49 46 37 13 29] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [53 85 32 83 76 49 46 37 13 29] , Agent2: [63 10 14 68 94  1 28 50 34 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [31 20 12 95 63 48 92 39 70 24] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [31 20 12 95 63 48 92 39 70 24] , Agent2: [11 40 42 83 38 16 69 72 63 27]\n",
      "winner is:  0\n",
      "Current state: Agent1: [73 41 26 15 11 18 66 69 89 75] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [73 41 26 15 11 18 66 69 89 75] , Agent2: [16 47 99  3 91 12 92 67 25 17]\n",
      "winner is:  0\n",
      "Current state: Agent1: [67 73 22 38 11 50 19 62 24 25] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [67 73 22 38 11 50 19 62 24 25] , Agent2: [59 29 77 66 32 54  0 83 56 44]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 20 25 87 33 33 41 22 53 15] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 20 25 87 33 33 41 22 53 15] , Agent2: [78 63 10 44  5  8 22 13 25 25]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 35 79 59 60 49 47 46 32 19] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 35 79 59 60 49 47 46 32 19] , Agent2: [86 17 80 69 60  2 53 91 39 25]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 9 78  4 49 56 21 15 64 61 39] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 9 78  4 49 56 21 15 64 61 39] , Agent2: [93 48 47 35 46 72 88 48 82 64]\n",
      "winner is:  0\n",
      "Current state: Agent1: [85 27 43 70 32 54 47 81 65 47] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [85 27 43 70 32 54 47 81 65 47] , Agent2: [ 0  6 90 60 88 40 67 36 47 53]\n",
      "winner is:  0\n",
      "Current state: Agent1: [61 53  1 77 87  2 22  4  8 36] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [61 53  1 77 87  2 22  4  8 36] , Agent2: [51 21 54 75  0  8 96 66 36 68]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 67  1 76 29 58 69 32 23 67] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 67  1 76 29 58 69 32 23 67] , Agent2: [88 25  8 41 26  1 68 16 23  5]\n",
      "winner is:  0\n",
      "Current state: Agent1: [83 15 29 21 67 16 56 30 27 80] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [83 15 29 21 67 16 56 30 27 80] , Agent2: [90 84 58 54 59 10 17 29 51 66]\n",
      "winner is:  0\n",
      "Current state: Agent1: [46 74 37  1 91 58 31 58 66 11] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [46 74 37  1 91 58 31 58 66 11] , Agent2: [90 13  9 87 59  5 76 43 68 23]\n",
      "winner is:  0\n",
      "Current state: Agent1: [41 20  6 43 65 71 20 52 23  6] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [41 20  6 43 65 71 20 52 23  6] , Agent2: [51  5 37 12 25 85 51 13 63 48]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 71 29 46 36 33 26 42 41 96] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 71 29 46 36 33 26 42 41 96] , Agent2: [27 45 66 34 45 28 68 18 13  9]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 40 82 43 14 70 21 63 39 91] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 40 82 43 14 70 21 63 39 91] , Agent2: [58 69 87 83 60 16 39 87 30 55]\n",
      "winner is:  0\n",
      "Current state: Agent1: [24 91 59 60 61 35 66 74 49  8] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [24 91 59 60 61 35 66 74 49  8] , Agent2: [86 66 82 20 37 12 39 65 24 94]\n",
      "winner is:  0\n",
      "Current state: Agent1: [37 83 29 49 88 30 56 88 55 68] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [37 83 29 49 88 30 56 88 55 68] , Agent2: [31  8 32 37 88 89 50 24 69 16]\n",
      "winner is:  0\n",
      "Average total reward -2000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pettingzoo.utils import random_demo\n",
    "random_demo(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lk\n"
     ]
    }
   ],
   "source": [
    "env = blotto_v0.env()\n",
    "\n",
    "env = to_parallel(env)\n",
    "#env = ss.pad_observations_v0(env) #needed for box\n",
    "\n",
    "env = ss.pettingzoo_env_to_vec_env_v0(env)\n",
    "\n",
    "env = ss.concat_vec_envs_v0(env, 1, num_cpus=2, base_class='stable_baselines3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 796      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 250      |\n",
      "| train/             |          |\n",
      "|    learning_rate   | 0.00025  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 681        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 0          |\n",
      "|    total_timesteps      | 500        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00199517 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -46.1      |\n",
      "|    explained_variance   | 1.09e-05   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.55e+03   |\n",
      "|    n_updates            | 4          |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    value_loss           | 1.72e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 654          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 750          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016561135 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.3         |\n",
      "|    n_updates            | 8            |\n",
      "|    policy_gradient_loss | -0.0328      |\n",
      "|    value_loss           | 91.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 650           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 1000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0021288514 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -46.1         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 38.5          |\n",
      "|    n_updates            | 12            |\n",
      "|    policy_gradient_loss | -0.0291       |\n",
      "|    value_loss           | 82.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 1250         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.300944e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.5         |\n",
      "|    n_updates            | 16           |\n",
      "|    policy_gradient_loss | -0.027       |\n",
      "|    value_loss           | 73.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 1500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018614002 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0244      |\n",
      "|    value_loss           | 61.5         |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 643            |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 1750           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00094871223 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    clip_range_vf        | 1              |\n",
      "|    entropy_loss         | -46.1          |\n",
      "|    explained_variance   | nan            |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 21.8           |\n",
      "|    n_updates            | 24             |\n",
      "|    policy_gradient_loss | -0.024         |\n",
      "|    value_loss           | 49.7           |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 642           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 2000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0021468366 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -46.1         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.3          |\n",
      "|    n_updates            | 28            |\n",
      "|    policy_gradient_loss | -0.0227       |\n",
      "|    value_loss           | 38.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 641          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 2250         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.004154424 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 32           |\n",
      "|    policy_gradient_loss | -0.028       |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 641          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 2500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.001636073 |\n",
      "|    clip_fraction        | 0.00108      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.9          |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -0.0256      |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 2750         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022559583 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.67         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 637          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 3000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021776664 |\n",
      "|    clip_fraction        | 0.00401      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.64         |\n",
      "|    n_updates            | 44           |\n",
      "|    policy_gradient_loss | -0.0273      |\n",
      "|    value_loss           | 8.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 3250         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.004588387 |\n",
      "|    clip_fraction        | 0.00832      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 48           |\n",
      "|    policy_gradient_loss | -0.0358      |\n",
      "|    value_loss           | 4.71         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 632           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 3500          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0029993267 |\n",
      "|    clip_fraction        | 0.0225        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -46.1         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.163         |\n",
      "|    n_updates            | 52            |\n",
      "|    policy_gradient_loss | -0.0434       |\n",
      "|    value_loss           | 2.38          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 3750         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.005039275 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.342       |\n",
      "|    n_updates            | 56           |\n",
      "|    policy_gradient_loss | -0.0543      |\n",
      "|    value_loss           | 0.899        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 625          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007652524 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.579       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0691      |\n",
      "|    value_loss           | 0.217        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 618         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4250        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | -0.01801876 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.602      |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.0852     |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.018510543 |\n",
      "|    clip_fraction        | 0.24         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.601       |\n",
      "|    n_updates            | 68           |\n",
      "|    policy_gradient_loss | -0.085       |\n",
      "|    value_loss           | 0.0168       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4750         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008566107 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.597       |\n",
      "|    n_updates            | 72           |\n",
      "|    policy_gradient_loss | -0.0807      |\n",
      "|    value_loss           | 0.0112       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 5000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | -0.00397176 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.607      |\n",
      "|    n_updates            | 76          |\n",
      "|    policy_gradient_loss | -0.0716     |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 5250        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012071657 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.595      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0728     |\n",
      "|    value_loss           | 0.0101      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 5500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008203438 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.609      |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.0764     |\n",
      "|    value_loss           | 0.00791     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 609           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 5750          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0020323703 |\n",
      "|    clip_fraction        | 0.17          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -46           |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.58         |\n",
      "|    n_updates            | 88            |\n",
      "|    policy_gradient_loss | -0.0566       |\n",
      "|    value_loss           | 0.0071        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 606          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054737087 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.585       |\n",
      "|    n_updates            | 92           |\n",
      "|    policy_gradient_loss | -0.0567      |\n",
      "|    value_loss           | 0.00679      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6250        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018467339 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.573      |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.0585     |\n",
      "|    value_loss           | 0.00598     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012407824 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.585      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0564     |\n",
      "|    value_loss           | 0.00455     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 601        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 6750       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02396706 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -46        |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.572     |\n",
      "|    n_updates            | 104        |\n",
      "|    policy_gradient_loss | -0.0519    |\n",
      "|    value_loss           | 0.00436    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 7000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015687654 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.578      |\n",
      "|    n_updates            | 108         |\n",
      "|    policy_gradient_loss | -0.0482     |\n",
      "|    value_loss           | 0.00391     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 7250        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005651661 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.0543     |\n",
      "|    value_loss           | 0.00331     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 7500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018705575 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.573      |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.0555     |\n",
      "|    value_loss           | 0.00377     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 596          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 7750         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144162355 |\n",
      "|    clip_fraction        | 0.217        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.584       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0629      |\n",
      "|    value_loss           | 0.0029       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007998537 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.581       |\n",
      "|    n_updates            | 124          |\n",
      "|    policy_gradient_loss | -0.0485      |\n",
      "|    value_loss           | 0.00296      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8250         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051042493 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.582       |\n",
      "|    n_updates            | 128          |\n",
      "|    policy_gradient_loss | -0.0559      |\n",
      "|    value_loss           | 0.00175      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 8500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008966928 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 132         |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    value_loss           | 0.00187     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 8750        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015628051 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.553      |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.0551     |\n",
      "|    value_loss           | 0.00184     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 582           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 9000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0018763542 |\n",
      "|    clip_fraction        | 0.193         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -46           |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.558        |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.0348       |\n",
      "|    value_loss           | 0.00179       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 580         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 9250        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010798552 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.603      |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0609     |\n",
      "|    value_loss           | 0.00162     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 580         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 9500        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011378389 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.578      |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.0539     |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 580          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 9750         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056728274 |\n",
      "|    clip_fraction        | 0.236        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.9        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.587       |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -0.0545      |\n",
      "|    value_loss           | 0.0012       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 579          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016921959 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.9        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.568       |\n",
      "|    n_updates            | 156          |\n",
      "|    policy_gradient_loss | -0.0331      |\n",
      "|    value_loss           | 0.00109      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 10250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021995917 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.575      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0537     |\n",
      "|    value_loss           | 0.00116     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 10500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017520403 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 164         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 0.000936    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 10750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004802117 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.567      |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.0502     |\n",
      "|    value_loss           | 0.000993    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 11000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007946143 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.588      |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | -0.0568     |\n",
      "|    value_loss           | 0.000773    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 572           |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 11250         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0031043538 |\n",
      "|    clip_fraction        | 0.273         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -45.9         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.579        |\n",
      "|    n_updates            | 176           |\n",
      "|    policy_gradient_loss | -0.0615       |\n",
      "|    value_loss           | 0.000842      |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 572        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 11500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02507317 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.9      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.582     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0449    |\n",
      "|    value_loss           | 0.00065    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 11750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013677395 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.576      |\n",
      "|    n_updates            | 184         |\n",
      "|    policy_gradient_loss | -0.0545     |\n",
      "|    value_loss           | 0.000684    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 12000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018974615 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.573      |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.0551     |\n",
      "|    value_loss           | 0.000596    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 12250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010647626 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.577      |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.0518     |\n",
      "|    value_loss           | 0.000596    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 12500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016128212 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.581      |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 0.000463    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 12750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012218431 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.565      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0497     |\n",
      "|    value_loss           | 0.000473    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 13000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014300388 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.578      |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.0445     |\n",
      "|    value_loss           | 0.000442    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 13250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021151142 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.59       |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.061      |\n",
      "|    value_loss           | 0.000406    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 13500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011109253 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 212         |\n",
      "|    policy_gradient_loss | -0.0454     |\n",
      "|    value_loss           | 0.000445    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 566        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 13750      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03176075 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.8      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.556     |\n",
      "|    n_updates            | 216        |\n",
      "|    policy_gradient_loss | -0.0445    |\n",
      "|    value_loss           | 0.000392   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 14000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024174007 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.56       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0558     |\n",
      "|    value_loss           | 0.00035     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 14250        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146692265 |\n",
      "|    clip_fraction        | 0.232        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.8        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.571       |\n",
      "|    n_updates            | 224          |\n",
      "|    policy_gradient_loss | -0.0319      |\n",
      "|    value_loss           | 0.000287     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 14500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020906243 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.586      |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.0533     |\n",
      "|    value_loss           | 0.000328    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 14750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024118286 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.565      |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.0489     |\n",
      "|    value_loss           | 0.000385    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 567          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 15000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078351535 |\n",
      "|    clip_fraction        | 0.258        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.8        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.579       |\n",
      "|    n_updates            | 236          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    value_loss           | 0.000314     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 15250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025827287 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.575      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0521     |\n",
      "|    value_loss           | 0.000279    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 568       |\n",
      "|    iterations           | 62        |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 15500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0204433 |\n",
      "|    clip_fraction        | 0.314     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    clip_range_vf        | 1         |\n",
      "|    entropy_loss         | -45.8     |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.56     |\n",
      "|    n_updates            | 244       |\n",
      "|    policy_gradient_loss | -0.0421   |\n",
      "|    value_loss           | 0.00025   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 15750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028776536 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.053      |\n",
      "|    value_loss           | 0.000276    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046339817 |\n",
      "|    clip_fraction        | 0.278        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.7        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.578       |\n",
      "|    n_updates            | 252          |\n",
      "|    policy_gradient_loss | -0.0565      |\n",
      "|    value_loss           | 0.000252     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 16250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016850773 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    value_loss           | 0.000211    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 16500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032072194 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 0.000208    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 16750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028078437 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.572      |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.043      |\n",
      "|    value_loss           | 0.000268    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 17000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030877352 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.545      |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    value_loss           | 0.000239    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 570        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 17250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01733828 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.7      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.579     |\n",
      "|    n_updates            | 272        |\n",
      "|    policy_gradient_loss | -0.0523    |\n",
      "|    value_loss           | 0.00024    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 17500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029221252 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.568      |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.0422     |\n",
      "|    value_loss           | 0.000214    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 17750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030453634 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0632     |\n",
      "|    value_loss           | 0.000235    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 18000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019525852 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.554      |\n",
      "|    n_updates            | 284         |\n",
      "|    policy_gradient_loss | -0.0494     |\n",
      "|    value_loss           | 0.000187    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 18250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040866673 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.585      |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 0.000214    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 571        |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 18500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02513776 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.7      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.569     |\n",
      "|    n_updates            | 292        |\n",
      "|    policy_gradient_loss | -0.052     |\n",
      "|    value_loss           | 0.000191   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 18750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039263837 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.54       |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 0.000205    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 19000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030188924 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 0.000214    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 571          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 19250        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012472011 |\n",
      "|    clip_fraction        | 0.258        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.7        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.543       |\n",
      "|    n_updates            | 304          |\n",
      "|    policy_gradient_loss | -0.0341      |\n",
      "|    value_loss           | 0.000192     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 19500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041189794 |\n",
      "|    clip_fraction        | 0.3          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.7        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.57        |\n",
      "|    n_updates            | 308          |\n",
      "|    policy_gradient_loss | -0.0461      |\n",
      "|    value_loss           | 0.000198     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 572        |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 19750      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02186984 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.56      |\n",
      "|    n_updates            | 312        |\n",
      "|    policy_gradient_loss | -0.0428    |\n",
      "|    value_loss           | 0.000198   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014894422 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.564      |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 0.000254    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 20250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028758084 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.575      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0503     |\n",
      "|    value_loss           | 0.000195    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 20500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107406555 |\n",
      "|    clip_fraction        | 0.29         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.6        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.544       |\n",
      "|    n_updates            | 324          |\n",
      "|    policy_gradient_loss | -0.0314      |\n",
      "|    value_loss           | 0.000184     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 20750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006597001 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.538      |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.0423     |\n",
      "|    value_loss           | 0.000212    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 21000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012348253 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.56       |\n",
      "|    n_updates            | 332         |\n",
      "|    policy_gradient_loss | -0.0497     |\n",
      "|    value_loss           | 0.00023     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 21250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035760157 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.562      |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 0.000217    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 21500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023528336 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 0.00017     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 573        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 21750      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01609177 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.5      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.571     |\n",
      "|    n_updates            | 344        |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    value_loss           | 0.00019    |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 573           |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 38            |\n",
      "|    total_timesteps      | 22000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0030897362 |\n",
      "|    clip_fraction        | 0.304         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    clip_range_vf        | 1             |\n",
      "|    entropy_loss         | -45.5         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | -0.571        |\n",
      "|    n_updates            | 348           |\n",
      "|    policy_gradient_loss | -0.0527       |\n",
      "|    value_loss           | 0.0002        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 22250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025151875 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.573      |\n",
      "|    n_updates            | 352         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 0.000207    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 573          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 22500        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021023205 |\n",
      "|    clip_fraction        | 0.325        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.5        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.565       |\n",
      "|    n_updates            | 356          |\n",
      "|    policy_gradient_loss | -0.0488      |\n",
      "|    value_loss           | 0.000231     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 22750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011313253 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0492     |\n",
      "|    value_loss           | 0.000162    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 23000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031570185 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.536      |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | -0.0511     |\n",
      "|    value_loss           | 0.000181    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 23250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032616533 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.545      |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 0.000192    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 23500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024921175 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 0.000164    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 23750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016051158 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.582      |\n",
      "|    n_updates            | 376         |\n",
      "|    policy_gradient_loss | -0.0573     |\n",
      "|    value_loss           | 0.000177    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 24000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022796195 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0552     |\n",
      "|    value_loss           | 0.000203    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 571        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 24250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01826874 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.4      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.577     |\n",
      "|    n_updates            | 384        |\n",
      "|    policy_gradient_loss | -0.0557    |\n",
      "|    value_loss           | 0.000201   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 24500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019867385 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.58       |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 0.000176    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 571        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 24750      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03719482 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.4      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.553     |\n",
      "|    n_updates            | 392        |\n",
      "|    policy_gradient_loss | -0.0463    |\n",
      "|    value_loss           | 0.000214   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 25000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011956013 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.0514     |\n",
      "|    value_loss           | 0.000186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 25250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032438114 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.554      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0596     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 25500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023452185 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.536      |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 0.000186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 25750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014285467 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    value_loss           | 0.000188    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 26000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028709527 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.576      |\n",
      "|    n_updates            | 412         |\n",
      "|    policy_gradient_loss | -0.0545     |\n",
      "|    value_loss           | 0.000197    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 571        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 26250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02571548 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.562     |\n",
      "|    n_updates            | 416        |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 0.00018    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 26500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044453457 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.000163    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 26750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025539272 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.54       |\n",
      "|    n_updates            | 424         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 0.000172    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 27000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027622424 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.0432     |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 570        |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 47         |\n",
      "|    total_timesteps      | 27250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04131416 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.3      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.548     |\n",
      "|    n_updates            | 432        |\n",
      "|    policy_gradient_loss | -0.0374    |\n",
      "|    value_loss           | 0.0002     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 27500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020148357 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.558      |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.0542     |\n",
      "|    value_loss           | 0.000174    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 570          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 27750        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053735734 |\n",
      "|    clip_fraction        | 0.345        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.2        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.567       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0374      |\n",
      "|    value_loss           | 0.000159     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 28000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030443275 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.574      |\n",
      "|    n_updates            | 444         |\n",
      "|    policy_gradient_loss | -0.0576     |\n",
      "|    value_loss           | 0.00017     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 570       |\n",
      "|    iterations           | 113       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 28250     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0178032 |\n",
      "|    clip_fraction        | 0.31      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    clip_range_vf        | 1         |\n",
      "|    entropy_loss         | -45.3     |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.561    |\n",
      "|    n_updates            | 448       |\n",
      "|    policy_gradient_loss | -0.0466   |\n",
      "|    value_loss           | 0.000147  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 28500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016532833 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.565      |\n",
      "|    n_updates            | 452         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 0.000213    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 28750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031449474 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.563      |\n",
      "|    n_updates            | 456         |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.000206    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 29000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028664587 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.559      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    value_loss           | 0.000182    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 29250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020760672 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.572      |\n",
      "|    n_updates            | 464         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    value_loss           | 0.000178    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 29500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028009508 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.547      |\n",
      "|    n_updates            | 468         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 0.000199    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 29750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010036236 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.569      |\n",
      "|    n_updates            | 472         |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 0.000188    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015193094 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.581      |\n",
      "|    n_updates            | 476         |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    value_loss           | 0.000194    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 570        |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 30250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03519985 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.559     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0515    |\n",
      "|    value_loss           | 0.00016    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 30500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022359606 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.58       |\n",
      "|    n_updates            | 484         |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    value_loss           | 0.000181    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 30750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008379195 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.574      |\n",
      "|    n_updates            | 488         |\n",
      "|    policy_gradient_loss | -0.0526     |\n",
      "|    value_loss           | 0.000196    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 31000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011694603 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.56       |\n",
      "|    n_updates            | 492         |\n",
      "|    policy_gradient_loss | -0.0413     |\n",
      "|    value_loss           | 0.000181    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 569        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 54         |\n",
      "|    total_timesteps      | 31250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02268875 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.578     |\n",
      "|    n_updates            | 496        |\n",
      "|    policy_gradient_loss | -0.0592    |\n",
      "|    value_loss           | 0.000153   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 569       |\n",
      "|    iterations           | 126       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 31500     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0334496 |\n",
      "|    clip_fraction        | 0.324     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    clip_range_vf        | 1         |\n",
      "|    entropy_loss         | -45.1     |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.578    |\n",
      "|    n_updates            | 500       |\n",
      "|    policy_gradient_loss | -0.0342   |\n",
      "|    value_loss           | 0.000177  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 31750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053500697 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.558      |\n",
      "|    n_updates            | 504         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032226846 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.543      |\n",
      "|    n_updates            | 508         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.000185    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 569        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 32250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03427959 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.564     |\n",
      "|    n_updates            | 512        |\n",
      "|    policy_gradient_loss | -0.0571    |\n",
      "|    value_loss           | 0.000187   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 569        |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 32500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03797442 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.555     |\n",
      "|    n_updates            | 516        |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 0.000178   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 569        |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 32750      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02841536 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.569     |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0561    |\n",
      "|    value_loss           | 0.000193   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 33000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012141792 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.557      |\n",
      "|    n_updates            | 524         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 0.000148    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 33250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038414627 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.565      |\n",
      "|    n_updates            | 528         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 33500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040725023 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.563      |\n",
      "|    n_updates            | 532         |\n",
      "|    policy_gradient_loss | -0.0433     |\n",
      "|    value_loss           | 0.000202    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 33750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027001897 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.545      |\n",
      "|    n_updates            | 536         |\n",
      "|    policy_gradient_loss | -0.0495     |\n",
      "|    value_loss           | 0.000154    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 34000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018587034 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0426     |\n",
      "|    value_loss           | 0.000183    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 34250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031889725 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 544         |\n",
      "|    policy_gradient_loss | -0.0534     |\n",
      "|    value_loss           | 0.000155    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 569        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 34500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01378495 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.558     |\n",
      "|    n_updates            | 548        |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    value_loss           | 0.000194   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 34750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023512714 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 552         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 0.000221    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 35000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023829514 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.534      |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    value_loss           | 0.000175    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 35250        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012750896 |\n",
      "|    clip_fraction        | 0.323        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.553       |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0492      |\n",
      "|    value_loss           | 0.000187     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 35500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018018976 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.564      |\n",
      "|    n_updates            | 564         |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    value_loss           | 0.000159    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 35750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024932759 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.547      |\n",
      "|    n_updates            | 568         |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    value_loss           | 0.000191    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 569       |\n",
      "|    iterations           | 144       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 36000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0135783 |\n",
      "|    clip_fraction        | 0.311     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    clip_range_vf        | 1         |\n",
      "|    entropy_loss         | -45.1     |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.57     |\n",
      "|    n_updates            | 572       |\n",
      "|    policy_gradient_loss | -0.0491   |\n",
      "|    value_loss           | 0.000167  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 36250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015906315 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.565      |\n",
      "|    n_updates            | 576         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    value_loss           | 0.000215    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 36500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020044656 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 0.000188    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 36750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028011654 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.563      |\n",
      "|    n_updates            | 584         |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    value_loss           | 0.000215    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 37000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019720944 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.559      |\n",
      "|    n_updates            | 588         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 0.000161    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 568        |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 37250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01151271 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.554     |\n",
      "|    n_updates            | 592        |\n",
      "|    policy_gradient_loss | -0.0446    |\n",
      "|    value_loss           | 0.000194   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 568        |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 37500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04060082 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.568     |\n",
      "|    n_updates            | 596        |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.000169   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 568        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 37750      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03406608 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.561     |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.000203   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 568        |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 38000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01870227 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.555     |\n",
      "|    n_updates            | 604        |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.000178   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 38250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034268685 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.574      |\n",
      "|    n_updates            | 608         |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    value_loss           | 0.000186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 38500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012011612 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.554      |\n",
      "|    n_updates            | 612         |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    value_loss           | 0.000187    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 38750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025809232 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.56       |\n",
      "|    n_updates            | 616         |\n",
      "|    policy_gradient_loss | -0.0566     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 39000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020632867 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.577      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0545     |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 568        |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 39250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02654451 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.566     |\n",
      "|    n_updates            | 624        |\n",
      "|    policy_gradient_loss | -0.0589    |\n",
      "|    value_loss           | 0.000148   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 39500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025343938 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 628         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    value_loss           | 0.000186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 39750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027375747 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.57       |\n",
      "|    n_updates            | 632         |\n",
      "|    policy_gradient_loss | -0.0514     |\n",
      "|    value_loss           | 0.000214    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044874143 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.576      |\n",
      "|    n_updates            | 636         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 0.000195    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 40250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025765345 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0548     |\n",
      "|    value_loss           | 0.000206    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 40500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023952162 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.554      |\n",
      "|    n_updates            | 644         |\n",
      "|    policy_gradient_loss | -0.0462     |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 40750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029784687 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 648         |\n",
      "|    policy_gradient_loss | -0.0583     |\n",
      "|    value_loss           | 0.000197    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 567          |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 41000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011254596 |\n",
      "|    clip_fraction        | 0.356        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    clip_range_vf        | 1            |\n",
      "|    entropy_loss         | -45.1        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.554       |\n",
      "|    n_updates            | 652          |\n",
      "|    policy_gradient_loss | -0.0419      |\n",
      "|    value_loss           | 0.000183     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 567        |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 72         |\n",
      "|    total_timesteps      | 41250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02995314 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.558     |\n",
      "|    n_updates            | 656        |\n",
      "|    policy_gradient_loss | -0.0447    |\n",
      "|    value_loss           | 0.000175   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 41500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022940611 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 0.000169    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 41750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038733505 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.541      |\n",
      "|    n_updates            | 664         |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 0.000159    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 42000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018309535 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 668         |\n",
      "|    policy_gradient_loss | -0.0437     |\n",
      "|    value_loss           | 0.000174    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 42250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025334856 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.574      |\n",
      "|    n_updates            | 672         |\n",
      "|    policy_gradient_loss | -0.0439     |\n",
      "|    value_loss           | 0.000213    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 42500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016852606 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 676         |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 0.000167    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 567       |\n",
      "|    iterations           | 171       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 42750     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0321009 |\n",
      "|    clip_fraction        | 0.348     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    clip_range_vf        | 1         |\n",
      "|    entropy_loss         | -44.9     |\n",
      "|    explained_variance   | nan       |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.554    |\n",
      "|    n_updates            | 680       |\n",
      "|    policy_gradient_loss | -0.0488   |\n",
      "|    value_loss           | 0.000171  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 43000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050131932 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 684         |\n",
      "|    policy_gradient_loss | -0.0493     |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 567        |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 43250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03492753 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.565     |\n",
      "|    n_updates            | 688        |\n",
      "|    policy_gradient_loss | -0.0494    |\n",
      "|    value_loss           | 0.00013    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 567        |\n",
      "|    iterations           | 174        |\n",
      "|    time_elapsed         | 76         |\n",
      "|    total_timesteps      | 43500      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03822392 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.566     |\n",
      "|    n_updates            | 692        |\n",
      "|    policy_gradient_loss | -0.0585    |\n",
      "|    value_loss           | 0.00014    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 43750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375063 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.566      |\n",
      "|    n_updates            | 696         |\n",
      "|    policy_gradient_loss | -0.0537     |\n",
      "|    value_loss           | 0.000157    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 44000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031442385 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.561      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 0.000169    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 566        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 44250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01489273 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.569     |\n",
      "|    n_updates            | 704        |\n",
      "|    policy_gradient_loss | -0.0426    |\n",
      "|    value_loss           | 0.00018    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 44500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013427774 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.561      |\n",
      "|    n_updates            | 708         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 0.000205    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 566        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 79         |\n",
      "|    total_timesteps      | 44750      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01404964 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.57      |\n",
      "|    n_updates            | 712        |\n",
      "|    policy_gradient_loss | -0.0501    |\n",
      "|    value_loss           | 0.000136   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 45000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028564122 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.567      |\n",
      "|    n_updates            | 716         |\n",
      "|    policy_gradient_loss | -0.0367     |\n",
      "|    value_loss           | 0.000179    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 45250       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014876733 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.554      |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    value_loss           | 0.000201    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 45500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011244807 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 724         |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 0.000162    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 45750       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019459011 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 728         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    value_loss           | 0.000179    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 46000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023777522 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.557      |\n",
      "|    n_updates            | 732         |\n",
      "|    policy_gradient_loss | -0.0447     |\n",
      "|    value_loss           | 0.000165    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 564        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 81         |\n",
      "|    total_timesteps      | 46250      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02203659 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    clip_range_vf        | 1          |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | nan        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.543     |\n",
      "|    n_updates            | 736        |\n",
      "|    policy_gradient_loss | -0.0483    |\n",
      "|    value_loss           | 0.000158   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 46500       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020314418 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    clip_range_vf        | 1           |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | nan         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.567      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0459     |\n",
      "|    value_loss           | 0.00018     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-b8376b29df94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MlpPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvf_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgae_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_range_vf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    278\u001b[0m     ) -> \"PPO\":\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         return super(PPO, self).learn(\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;31m# Normalize advantage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mevaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \"\"\"\n\u001b[1;32m    609\u001b[0m         \u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36m_get_action_dist_from_latent\u001b[0;34m(self, latent_pi, latent_sde)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiCategoricalDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;31m# Here mean_actions are the flattened logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBernoulliDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;31m# Here mean_actions are the logits (before rounding to get the binary actions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, action_logits)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_logits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"MultiCategoricalDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_logits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"MultiCategoricalDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rlenv/lib/python3.8/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`logits` parameter must be at least one-dimensional.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=3, gamma=0.99, n_steps=125, ent_coef=0.01, learning_rate=0.00025, vf_coef=0.5, max_grad_norm=0.5, gae_lambda=0.95, n_epochs=4, clip_range=0.2, clip_range_vf=1)\n",
    "model.learn(total_timesteps=2000000)\n",
    "model.save(\"policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lk\n",
      "Current state: Agent1: [36  5  0 63 78 27  3 54 60 86] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [36  5  0 63 78 27  3 54 60 86] , Agent2: [64 79 15 28 84 37 10 61  2 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [27 20 43 69 64  1 75 22  2  3] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [27 20 43 69 64  1 75 22  2  3] , Agent2: [76 85 24 24  7 35 36 27 62 67]\n",
      "winner is:  0\n",
      "Current state: Agent1: [31 10 65  7 15 37 88 69  4 37] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [31 10 65  7 15 37 88 69  4 37] , Agent2: [53 75 21 49 14 89  7 17 51 26]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 53 93 67 95 58 52  9 18 81] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [43 53 93 67 95 58 52  9 18 81] , Agent2: [63  8 83 60 95 41 60 98 49 87]\n",
      "winner is:  0\n",
      "Current state: Agent1: [80 24 59 40 73 67 75 49 73 25] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [80 24 59 40 73 67 75 49 73 25] , Agent2: [97 65 76 14 13 59 30 59 22 31]\n",
      "winner is:  0\n",
      "Current state: Agent1: [88 83  2 45 79 58 27 87 53 64] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [88 83  2 45 79 58 27 87 53 64] , Agent2: [66 14 84 83 57 55 78 43 59 41]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 68 80 18 84 72 89 27 60 14] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 2 68 80 18 84 72 89 27 60 14] , Agent2: [29 92 73 45 47 57 55 81 27 63]\n",
      "winner is:  0\n",
      "Current state: Agent1: [48 69 23 28 73  6 67 32 29 18] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [48 69 23 28 73  6 67 32 29 18] , Agent2: [73 42 66 73 74 69 48 12  2 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [55 52 81  4 93 86 61  9  5 33] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [55 52 81  4 93 86 61  9  5 33] , Agent2: [17 28 57 73 48 50  6 45 21 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [71 32 84 42 69 92 45 66 30 31] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [71 32 84 42 69 92 45 66 30 31] , Agent2: [24 83  0 96 48 43 40  2 40 26]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 34 65 20 73 34 20 85 49 71] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 34 65 20 73 34 20 85 49 71] , Agent2: [ 3 97 40 67 32 84 17 34 43 62]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 6 14 50 91  3 93 64 63 45  2] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 6 14 50 91  3 93 64 63 45  2] , Agent2: [57 54  5 47 99 58 63 39 37 62]\n",
      "winner is:  0\n",
      "Current state: Agent1: [58 20 72 40 56 86 72 41 94 94] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [58 20 72 40 56 86 72 41 94 94] , Agent2: [ 0 77 74 14 90 32 60 75 86 26]\n",
      "winner is:  0\n",
      "Current state: Agent1: [78  2 64 14 87  0 30 82 26 71] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [78  2 64 14 87  0 30 82 26 71] , Agent2: [ 6 91 64 30 47 88 93  5 58 86]\n",
      "winner is:  0\n",
      "Current state: Agent1: [54 99 20 91 84 13  1 35 61 69] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [54 99 20 91 84 13  1 35 61 69] , Agent2: [14 72 51 46  3  6 59  2 51 65]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10  2 81 67 99 31 79 73 79  0] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10  2 81 67 99 31 79 73 79  0] , Agent2: [53 74 64 87 69 52 34 80  3 50]\n",
      "winner is:  0\n",
      "Current state: Agent1: [27 74 44 62 55 12 44 37 39 28] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [27 74 44 62 55 12 44 37 39 28] , Agent2: [46 47 26 68 69 79 30 70 53 85]\n",
      "winner is:  0\n",
      "Current state: Agent1: [76 76 74 10 77 94 53 63 15 57] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [76 76 74 10 77 94 53 63 15 57] , Agent2: [ 8  5 64 41 30 56 59 95 24 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [16 32 85 32 62 30 65 18 52 93] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [16 32 85 32 62 30 65 18 52 93] , Agent2: [74 57 78 56 21 57 40 66 30 26]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 35 65 70 52 33  9 69 15 87] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 35 65 70 52 33  9 69 15 87] , Agent2: [41 79 10 62 68  0 30 32 36 91]\n",
      "winner is:  0\n",
      "Current state: Agent1: [92 35 40 45 39 14 99  1 23 71] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [92 35 40 45 39 14 99  1 23 71] , Agent2: [ 5 66 55 10 39  2 61  7 70 87]\n",
      "winner is:  0\n",
      "Current state: Agent1: [89 29  6 35 64  9 40  5 99 18] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [89 29  6 35 64  9 40  5 99 18] , Agent2: [40  9 50 88 42 52 40 20 71 40]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 60 80 18 80 60 96 69 89 69] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 60 80 18 80 60 96 69 89 69] , Agent2: [26 10 40 49 74 81 75 44 65  0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [71 72 23 19 52 62 80 45 26 26] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [71 72 23 19 52 62 80 45 26 26] , Agent2: [76 93 10 32 95 58 81  9 28 55]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 90 73 89 57  9 60 77 53 10] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 90 73 89 57  9 60 77 53 10] , Agent2: [34 91 42 46 92  9 79 72 51 41]\n",
      "winner is:  0\n",
      "Current state: Agent1: [72 21  1 45 64  9 40 13 67 22] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [72 21  1 45 64  9 40 13 67 22] , Agent2: [84 24 14 80 79 75 71 80 26 96]\n",
      "winner is:  0\n",
      "Current state: Agent1: [94 18 99 40 91 64 13 27 73 62] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [94 18 99 40 91 64 13 27 73 62] , Agent2: [43 52 18 98  7 95 78  0 76  5]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5  9 87 41 91  4 82 56 50  9] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5  9 87 41 91  4 82 56 50  9] , Agent2: [ 7  5 90 39 24 57 22 43 81 14]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 46  9 62  7 66 50 93 11 25] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 46  9 62  7 66 50 93 11 25] , Agent2: [94 55 54 96 81 78 44 71 24 76]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 88 42 64  4 70 89 61 51 15] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 88 42 64  4 70 89 61 51 15] , Agent2: [ 7 82  7 25 10 63 95 14 42 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [91 12 49 48 97 99 44 16 89 50] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [91 12 49 48 97 99 44 16 89 50] , Agent2: [81 25 94 64 93  1 62 63 68 88]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 76 22  7 14 27 96 58 58 41] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 76 22  7 14 27 96 58 58 41] , Agent2: [19 80 63 57 74 89 29 66 24 23]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 94 18 78 81 18 32 27 44 48] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 94 18 78 81 18 32 27 44 48] , Agent2: [17 83 59 46 65 19 93 82  2 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [85 75 29 65 12 88 61 60 73 77] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [85 75 29 65 12 88 61 60 73 77] , Agent2: [75 78 32 88 99 29 81 10 59 59]\n",
      "winner is:  0\n",
      "Current state: Agent1: [71 58 90 73 11 95 95 91 59 88] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [71 58 90 73 11 95 95 91 59 88] , Agent2: [53 75 33  0 98 64 89 17 67 81]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 74 59 11 81 77 78 27 20 27] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 74 59 11 81 77 78 27 20 27] , Agent2: [ 8 68 99  8  3 35 12 62 67 81]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 11 44 45 60 58 20 25 72  2] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 11 44 45 60 58 20 25 72  2] , Agent2: [13 67 81 24 65  2 30  4 83  5]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 81 50 63 99 51 30 31 79 80] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 81 50 63 99 51 30 31 79 80] , Agent2: [19 37 38 45  0 86 93 48  8 42]\n",
      "winner is:  0\n",
      "Current state: Agent1: [96 36 52  5 79 10 52 61 88 42] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [96 36 52  5 79 10 52 61 88 42] , Agent2: [ 4 93 85 75 95 92 76 66  1 54]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 97 99  1 12 57 29 13 33 85] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 97 99  1 12 57 29 13 33 85] , Agent2: [ 7 17 97 18  4 36 26 80 93 83]\n",
      "winner is:  0\n",
      "Current state: Agent1: [49 60 10 20 26 98 94 68 15 31] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [49 60 10 20 26 98 94 68 15 31] , Agent2: [87 31 24 82 48 43 96  3 67  1]\n",
      "winner is:  0\n",
      "Current state: Agent1: [31 24 74 88 75 98 94 68 90 86] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [31 24 74 88 75 98 94 68 90 86] , Agent2: [67 66 11 14 51 39 83 21 12 15]\n",
      "winner is:  0\n",
      "Current state: Agent1: [29 95 23 14 42 10 81 44  5 68] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [29 95 23 14 42 10 81 44  5 68] , Agent2: [64 97 34 67 37 60 65  6 50 82]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 55 23 14 95 39 30 33 76 88] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [64 55 23 14 95 39 30 33 76 88] , Agent2: [55 74 16 90 42 24 45 91 67 47]\n",
      "winner is:  0\n",
      "Current state: Agent1: [52 37 39  7 47 86 18 52 18 55] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [52 37 39  7 47 86 18 52 18 55] , Agent2: [ 0 97 23 40 10 10 25 73 56 99]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44  3 44 24 71 35 94 11 98  2] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [44  3 44 24 71 35 94 11 98  2] , Agent2: [ 6 10 39 47 72 37 93 89 96 77]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 99 85 29 21 68 24  9 77 23] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 99 85 29 21 68 24  9 77 23] , Agent2: [78 99 79 80 25 92  6 12 33 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 20 16 19 56 15 95 49 66  7] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 20 16 19 56 15 95 49 66  7] , Agent2: [22 32 24 85  7 60  5 61 85 31]\n",
      "winner is:  0\n",
      "Current state: Agent1: [45 56 15 45 55 81 34  2 48 26] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [45 56 15 45 55 81 34  2 48 26] , Agent2: [63 74  2 42 37 71 17 65 83 74]\n",
      "winner is:  0\n",
      "Current state: Agent1: [40 69 16 35 20 38 25 86 15  5] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [40 69 16 35 20 38 25 86 15  5] , Agent2: [ 1 97  0 10  2 39 47 48 52 90]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 64 89 78 30 85  4 82  6 44] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 64 89 78 30 85  4 82  6 44] , Agent2: [78 36  7 98 14 99 17 27 22 76]\n",
      "winner is:  0\n",
      "Current state: Agent1: [65 98 66 82 75 13 65  1 22 60] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [65 98 66 82 75 13 65  1 22 60] , Agent2: [78 20 18 91 25 23 79 58 22 51]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 6 99 38 42 54 24  5 40 62 82] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 6 99 38 42 54 24  5 40 62 82] , Agent2: [44 37 40 78 62  1 59 22 80 26]\n",
      "winner is:  0\n",
      "Current state: Agent1: [42 59 87  4 27 74 76 68 96 84] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [42 59 87  4 27 74 76 68 96 84] , Agent2: [29 34 83 25 88 68 56  9 46 91]\n",
      "winner is:  0\n",
      "Current state: Agent1: [29 14 63 46  0 52 17 74 78 48] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [29 14 63 46  0 52 17 74 78 48] , Agent2: [21 97 66  1 82 76 96 84 98 90]\n",
      "winner is:  0\n",
      "Current state: Agent1: [12 40 63 56 11 83 19 35 58 73] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [12 40 63 56 11 83 19 35 58 73] , Agent2: [84  6 18 73 22  1 80 63 82 62]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 23 36 50 74 80 95 85 55 97] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 23 36 50 74 80 95 85 55 97] , Agent2: [54 66 64 32 70 29 21 66 43 24]\n",
      "winner is:  0\n",
      "Current state: Agent1: [33 37 87 62 65  4 41 75 87 82] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [33 37 87 62 65  4 41 75 87 82] , Agent2: [59 48 46 35  1 65 56 48  7 42]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 51 55 93 24 79 30 20 79 79] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 51 55 93 24 79 30 20 79 79] , Agent2: [41 24 78 46 49 98 21 10 90 41]\n",
      "winner is:  0\n",
      "Current state: Agent1: [98 68 45 77 17 65 24 71 37 74] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [98 68 45 77 17 65 24 71 37 74] , Agent2: [ 6 42 30 69 43 15 95  1 92 26]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 20  0 50 87 23 34 15 89 47] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 20  0 50 87 23 34 15 89 47] , Agent2: [17 61 84  9 94 29 90  9 62 69]\n",
      "winner is:  0\n",
      "Current state: Agent1: [39 52 91 13  3  1 22 66 26 60] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [39 52 91 13  3  1 22 66 26 60] , Agent2: [64 42  7 46 37 80 40 67 45 13]\n",
      "winner is:  0\n",
      "Current state: Agent1: [63 34 82  7  7 75 33 34 82 73] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [63 34 82  7  7 75 33 34 82 73] , Agent2: [ 0 81 99 79 14  9 89 69 73 20]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 66 22 39 54 79 17 34 98  8] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [87 66 22 39 54 79 17 34 98  8] , Agent2: [69 68 95 49 81 25 51  7 26 49]\n",
      "winner is:  0\n",
      "Current state: Agent1: [25 72 18  0  7 48  6  7 95 74] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [25 72 18  0  7 48  6  7 95 74] , Agent2: [54 75 64 77 48 10 76 66 48 47]\n",
      "winner is:  0\n",
      "Current state: Agent1: [96 82  8 39  0 31 56 28 47 91] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [96 82  8 39  0 31 56 28 47 91] , Agent2: [23 75 84 10 99 57 83 10 26 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 74  8 58 68 43 41 53 48 17] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 74  8 58 68 43 41 53 48 17] , Agent2: [50 68 64 14 35 54 21 14 83 11]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 75 65  0 74 83 31 14 10 30] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 75 65  0 74 83 31 14 10 30] , Agent2: [10 38 95 14 24 63 45 71 24 37]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 22 10  0 77 39 12 63  5 23] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [10 22 10  0 77 39 12 63  5 23] , Agent2: [86 91 91 28 31 86 30 92 41 38]\n",
      "winner is:  0\n",
      "Current state: Agent1: [77 55 30 50 46  2  9 34 70 24] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [77 55 30 50 46  2  9 34 70 24] , Agent2: [84 58 95 82 28 34 94  4 50  8]\n",
      "winner is:  0\n",
      "Current state: Agent1: [62  8 24 94 64 25 45 92 62 76] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [62  8 24 94 64 25 45 92 62 76] , Agent2: [ 8 97 51 95 91  5 53 44  0 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [58 77 26 67 69 30 62 44 80 43] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [58 77 26 67 69 30 62 44 80 43] , Agent2: [11 50 13  2 52 35 88 57 67 15]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 25 94  2 73 63 53 89 26 68] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [18 25 94  2 73 63 53 89 26 68] , Agent2: [59 39 57 30 68 70 95 11 49 97]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 91  6 39 36  1 82 74 55 30] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [23 91  6 39 36  1 82 74 55 30] , Agent2: [17 17 81  3 37 87 13 70 24 51]\n",
      "winner is:  0\n",
      "Current state: Agent1: [82 44 17 50 74 44  5 82 49 26] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [82 44 17 50 74 44  5 82 49 26] , Agent2: [21 23 24 35 53 85 59 35 65 30]\n",
      "winner is:  0\n",
      "Current state: Agent1: [84 74 81 25 86 48 21 15  4  1] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [84 74 81 25 86 48 21 15  4  1] , Agent2: [16 48 52 60 95 70 45  6 77 23]\n",
      "winner is:  0\n",
      "Current state: Agent1: [35 18 37 60 97 40 79 65 96 82] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [35 18 37 60 97 40 79 65 96 82] , Agent2: [ 7  9 99 45 73  8 76 86 62 39]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 60 14 59 90 83 30 70 80 41] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [50 60 14 59 90 83 30 70 80 41] , Agent2: [55 54 25 11 12 15  4 87 66 46]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 72  6  4 31 64 89 25 57 49] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 72  6  4 31 64 89 25 57 49] , Agent2: [93  3 52 62 99 80 14 69 44 94]\n",
      "winner is:  0\n",
      "Current state: Agent1: [81 39 99 44 28 47 61 63 68 15] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [81 39 99 44 28 47 61 63 68 15] , Agent2: [64 37 76 20  1 33 73 73 37 88]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 32 24 78 12 92 24 90 60 37] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [90 32 24 78 12 92 24 90 60 37] , Agent2: [33 18 37 73 39 60 30 88 17 37]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 92 82 41 42 44 49 46 41 83] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [19 92 82 41 42 44 49 46 41 83] , Agent2: [21 29 45 24 17 92 43 40 59 96]\n",
      "winner is:  0\n",
      "Current state: Agent1: [54 40 81 11 24 85 89 76 88 87] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [54 40 81 11 24 85 89 76 88 87] , Agent2: [78 45 15 30 80 76 75 91 27 26]\n",
      "winner is:  0\n",
      "Current state: Agent1: [92 11 74 18 14 92 34 28 64 69] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [92 11 74 18 14 92 34 28 64 69] , Agent2: [10 91 68 67 91 18 63  3 24 87]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 88 76 22 62 11 89 38 96 75] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 5 88 76 22 62 11 89 38 96 75] , Agent2: [38 16  2 74 66 30 29 17 72  8]\n",
      "winner is:  0\n",
      "Current state: Agent1: [84  6 18 88 10 86 29 47 45 50] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: Agent1: [84  6 18 88 10 86 29 47 45 50] , Agent2: [33 91 18 47 96  9 95 55 22 24]\n",
      "winner is:  0\n",
      "Current state: Agent1: [78 30 41 82 75 44 78 67 66 13] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [78 30 41 82 75 44 78 67 66 13] , Agent2: [97 89  4 17 42 65 91 11 42 25]\n",
      "winner is:  0\n",
      "Current state: Agent1: [59 44  4 47 41 61 68 27  5 50] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [59 44  4 47 41 61 68 27  5 50] , Agent2: [ 8 31 58 69 24  5 12 98 51 19]\n",
      "winner is:  0\n",
      "Current state: Agent1: [34 28 27 47 64 86  7 45  1 33] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [34 28 27 47 64 86  7 45  1 33] , Agent2: [18 60 40 24 69 57 93 61  0 83]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 35 13 36 85 59 41 79 74 23] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [17 35 13 36 85 59 41 79 74 23] , Agent2: [67 83  2 63 24 86 82  4 22 53]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 7 88 59 81 81 30 40 46  8 26] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 7 88 59 81 81 30 40 46  8 26] , Agent2: [68 14 87 36 79 56 13 33 69 60]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 13 22 41 78 16 91 54 39 15] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [ 1 13 22 41 78 16 91 54 39 15] , Agent2: [97 80 91 47 95 13 93 92  5 71]\n",
      "winner is:  0\n",
      "Current state: Agent1: [12 97 96 73 57 75  3 21 11 51] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [12 97 96 73 57 75  3 21 11 51] , Agent2: [ 3  7 27 80 42 42 38 69  6 82]\n",
      "winner is:  0\n",
      "Current state: Agent1: [61 75 50 70 83 58 26 84 28 82] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [61 75 50 70 83 58 26 84 28 82] , Agent2: [ 4 72 64  0 11 35 21 27 92 62]\n",
      "winner is:  0\n",
      "Current state: Agent1: [56 17 27 47  6 15 44 73 67 39] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [56 17 27 47  6 15 44 73 67 39] , Agent2: [ 4 86 60 45 71 60 49 20 96 62]\n",
      "winner is:  0\n",
      "Current state: Agent1: [30 41 99  9 54 45 44 63 33 97] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [30 41 99  9 54 45 44 63 33 97] , Agent2: [27 19 64 37 68 84  5  5  7 47]\n",
      "winner is:  0\n",
      "Current state: Agent1: [55  2 76 36 48 52 64 65 62 55] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [55  2 76 36 48 52 64 65 62 55] , Agent2: [92 95  9 44 42  5 49 64 59 22]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 10 83 47 79 83 89  6 47 40] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [11 10 83 47 79 83 89  6 47 40] , Agent2: [96 76 21 73 58 60 38  7 79 22]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 36 54 45 14 25 50 43 89 26] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [66 36 54 45 14 25 50 43 89 26] , Agent2: [76  0 99 32 26 98 53 52 78 23]\n",
      "winner is:  0\n",
      "Current state: Agent1: [58 60 47 88 95 53 87 91 67 26] , Agent2: [0 0 0 0 0 0 0 0 0 0]\n",
      "winner is:  0\n",
      "Current state: Agent1: [58 60 47 88 95 53 87 91 67 26] , Agent2: [19 13 41 35 61 44 96 94 94 25]\n",
      "winner is:  0\n"
     ]
    }
   ],
   "source": [
    "env =  blotto_v0.env()\n",
    "#env = to_parallel(env)\n",
    "\n",
    "#env = ss.pad_observations_v0(env)\n",
    "\n",
    "#env = ss.agent_indicator_v0(env)\n",
    "\n",
    "env.reset()\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    act = model.predict(obs)[0] if not done else None\n",
    "    env.step(act)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([100,100,100,100,100]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100, 100, 100, 100]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[100 for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([23 ,17 ,17, 16, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([7, 17, 17, 16, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
